"""
ê°„ì†Œí™”ëœ ì‹¤ì‹œê°„ ìš´ë™ ë¶„ì„ê¸°
- í›ˆë ¨ëœ ëª¨ë¸ë¡œ ìš´ë™ ìë™ ë¶„ë¥˜
- ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ (good/bad)
- ì§ê´€ì  ë¹„ì£¼ì–¼ í”¼ë“œë°±
"""

import cv2
import numpy as np
import mediapipe as mp
import time
from collections import deque
import json
from typing import Dict, List, Tuple, Optional
import argparse
import tempfile
import os
import sys

def import_modules():
    """í•„ìš”í•œ ëª¨ë“ˆë“¤ import"""
    try:
        from exercise_classifier import ExerciseClassificationModel
        from pose_analysis_system import ExerciseClassifier, PostProcessor
        return ExerciseClassificationModel, ExerciseClassifier, PostProcessor
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
        print("í•„ìš”í•œ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("  - exercise_classifier.py")
        print("  - pose_analysis_system.py")
        return None, None, None

class SimplifiedRealTimeAnalyzer:
    """ê°„ì†Œí™”ëœ ì‹¤ì‹œê°„ ë¶„ì„ê¸°"""
    
    def __init__(self, model_path: str = "models/exercise_classifier.pkl"):
        # ëª¨ë“ˆ import
        ExerciseClassificationModel, ExerciseClassifier, PostProcessor = import_modules()
        if not all([ExerciseClassificationModel, ExerciseClassifier, PostProcessor]):
            self.init_success = False
            return
        
        # MediaPipe ì´ˆê¸°í™”
        try:
            self.mp_pose = mp.solutions.pose
            self.pose = self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=1,
                enable_segmentation=False,
                min_detection_confidence=0.7,
                min_tracking_confidence=0.5
            )
            self.mp_drawing = mp.solutions.drawing_utils
            self.mp_drawing_styles = mp.solutions.drawing_styles
        except Exception as e:
            print(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.init_success = False
            return
        
        # ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ
        self.exercise_classifier = ExerciseClassificationModel()
        self.model_loaded = False
        
        if os.path.exists(model_path):
            self.model_loaded = self.exercise_classifier.load_model(model_path)
            if self.model_loaded:
                print(f"âœ… ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            else:
                print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_path}")
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            print("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”: python main.py --mode train")
        
        # ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
        try:
            self.pose_analyzer = ExerciseClassifier()
            self.post_processor = PostProcessor(hysteresis_threshold=0.2, ema_alpha=0.3)
        except Exception as e:
            print(f"âŒ ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.init_success = False
            return
        
        # í˜„ì¬ ìƒíƒœ
        self.current_exercise = "detecting..."
        self.current_pose_quality = "unknown"
        self.classification_confidence = 0.0
        self.pose_confidence = 0.0
        
        # ì•ˆì •í™”ë¥¼ ìœ„í•œ íˆìŠ¤í† ë¦¬
        self.exercise_history = deque(maxlen=15)  # ìš´ë™ ë¶„ë¥˜ ì•ˆì •í™”
        self.pose_history = deque(maxlen=5)       # ìì„¸ ë¶„ì„ ì•ˆì •í™”
        
        # íƒ€ì´ë° ì œì–´
        self.last_classification_time = 0
        self.classification_interval = 2.0  # 2ì´ˆë§ˆë‹¤ ìš´ë™ ë¶„ë¥˜
        
        # í†µê³„
        self.good_count = 0
        self.bad_count = 0
        
        # ì„ì‹œ íŒŒì¼ ë””ë ‰í† ë¦¬
        self.temp_dir = tempfile.mkdtemp()
        
        self.init_success = True
    
    def classify_current_exercise(self, frame: np.ndarray) -> Tuple[str, float]:
        """í˜„ì¬ í”„ë ˆì„ì˜ ìš´ë™ ë¶„ë¥˜"""
        current_time = time.time()
        
        # ë¶„ë¥˜ ì£¼ê¸° ì œì–´ (2ì´ˆë§ˆë‹¤)
        if current_time - self.last_classification_time < self.classification_interval:
            return self.current_exercise, self.classification_confidence
        
        if not self.model_loaded:
            return "model_not_loaded", 0.0
        
        try:
            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            temp_path = os.path.join(self.temp_dir, "current_frame.jpg")
            cv2.imwrite(temp_path, frame)
            
            # ìš´ë™ ë¶„ë¥˜
            exercise, confidence = self.exercise_classifier.predict(temp_path)
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.exercise_history.append((exercise, confidence))
            
            # ì•ˆì •í™”: ìµœê·¼ ê²°ê³¼ë“¤ì˜ í•©ì˜
            if len(self.exercise_history) >= 5:
                # ì‹ ë¢°ë„ 0.4 ì´ìƒì¸ ì˜ˆì¸¡ë“¤ë§Œ ê³ ë ¤
                recent_predictions = [(ex, conf) for ex, conf in list(self.exercise_history)[-10:] 
                                    if conf > 0.4]
                
                if recent_predictions:
                    # ê°€ì¥ ìì£¼ ë‚˜ì˜¨ ìš´ë™ ì„ íƒ
                    from collections import Counter
                    exercises = [ex for ex, conf in recent_predictions]
                    most_common = Counter(exercises).most_common(1)[0]
                    
                    if most_common[1] >= 3:  # ìµœì†Œ 3ë²ˆ ì´ìƒ ë‚˜ì˜¨ ê²½ìš°ë§Œ
                        new_exercise = most_common[0]
                        
                        # ìš´ë™ì´ ë°”ë€ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
                        if new_exercise != self.current_exercise:
                            self.current_exercise = new_exercise
                            self.classification_confidence = confidence
                            print(f"ğŸ¯ ìš´ë™ ê°ì§€: {new_exercise.upper()} (ì‹ ë¢°ë„: {confidence:.2f})")
            
            self.last_classification_time = current_time
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_path):
                os.remove(temp_path)
            
            return self.current_exercise, self.classification_confidence
            
        except Exception as e:
            print(f"ìš´ë™ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return self.current_exercise, self.classification_confidence
    
    def analyze_pose_quality(self, landmarks) -> Tuple[str, Dict]:
        """ìì„¸ í’ˆì§ˆ ë¶„ì„"""
        if self.current_exercise in ["detecting...", "model_not_loaded", "unknown"]:
            return "waiting", {}
        
        try:
            # ëœë“œë§ˆí¬ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            landmarks_dict = []
            for landmark in landmarks:
                landmarks_dict.append({
                    'x': landmark.x,
                    'y': landmark.y,
                    'z': landmark.z,
                    'visibility': landmark.visibility
                })
            
            # ìì„¸ ë¶„ì„
            analysis = self.pose_analyzer.analyze_pose(landmarks_dict, self.current_exercise)
            if not analysis['valid']:
                return "invalid", {}
            
            # í›„ì²˜ë¦¬ ì ìš©
            final_result = self.post_processor.process(analysis)
            pose_quality = final_result['final_classification']
            self.pose_confidence = final_result.get('confidence', 0.0)
            
            # ì•ˆì •í™”
            self.pose_history.append(pose_quality)
            
            if len(self.pose_history) >= 3:
                recent_poses = list(self.pose_history)[-3:]
                good_count = recent_poses.count('good')
                self.current_pose_quality = 'good' if good_count >= 2 else 'bad'
            else:
                self.current_pose_quality = pose_quality
            
            return self.current_pose_quality, final_result
            
        except Exception as e:
            print(f"ìì„¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "error", {}
    
    def draw_enhanced_feedback(self, image: np.ndarray, exercise: str, pose_quality: str, 
                             classification_conf: float, pose_conf: float, 
                             analysis_result: Dict) -> np.ndarray:
        """í–¥ìƒëœ ë¹„ì£¼ì–¼ í”¼ë“œë°±"""
        height, width = image.shape[:2]
        
        # ğŸ¯ ë©”ì¸ ìƒíƒœì— ë”°ë¥¸ í…Œë‘ë¦¬ ìƒ‰ìƒ
        if exercise in ["detecting...", "model_not_loaded"]:
            border_color = (255, 255, 0)  # ë…¸ë€ìƒ‰: ëŒ€ê¸°ì¤‘
            status_text = "DETECTING EXERCISE..."
        elif pose_quality == "good":
            border_color = (0, 255, 0)    # ì´ˆë¡ìƒ‰: ì¢‹ì€ ìì„¸
            status_text = "EXCELLENT FORM!"
        elif pose_quality == "bad":
            border_color = (0, 0, 255)    # ë¹¨ê°„ìƒ‰: ë‚˜ìœ ìì„¸
            status_text = "IMPROVE FORM!"
        else:
            border_color = (128, 128, 128) # íšŒìƒ‰: ë¶„ì„ì¤‘
            status_text = "ANALYZING..."
        
        # ë‘êº¼ìš´ í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
        border_thickness = 20
        cv2.rectangle(image, (0, 0), (width, height), border_color, border_thickness)
        
        # ğŸ¯ ìƒë‹¨ ì •ë³´ íŒ¨ë„
        panel_height = 120
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (width, panel_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)
        
        # ìš´ë™ ì¢…ëª© í‘œì‹œ
        if exercise not in ["detecting...", "model_not_loaded"]:
            exercise_text = f"EXERCISE: {exercise.upper().replace('_', ' ')}"
            cv2.putText(image, exercise_text, (30, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
            
            # ë¶„ë¥˜ ì‹ ë¢°ë„
            conf_text = f"Confidence: {classification_conf:.1%}"
            cv2.putText(image, conf_text, (30, 75), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ğŸ¯ ì¤‘ì•™ ìƒíƒœ í‘œì‹œ
        status_size = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 3)[0]
        status_x = (width - status_size[0]) // 2
        status_y = height // 2 - 100
        
        # ìƒíƒœ í…ìŠ¤íŠ¸ ë°°ê²½
        cv2.rectangle(image, (status_x - 20, status_y - 40), 
                     (status_x + status_size[0] + 20, status_y + 10), (0, 0, 0), -1)
        
        cv2.putText(image, status_text, (status_x, status_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, border_color, 3)
        
        # ğŸ“Š í•˜ë‹¨ í†µê³„ íŒ¨ë„
        if exercise not in ["detecting...", "model_not_loaded"]:
            total_frames = self.good_count + self.bad_count
            if total_frames > 0:
                good_ratio = self.good_count / total_frames
                
                stats_y = height - 80
                cv2.rectangle(image, (0, stats_y), (width, height), (0, 0, 0), -1)
                
                stats_text = f"GOOD: {self.good_count}  |  BAD: {self.bad_count}  |  SUCCESS RATE: {good_ratio:.1%}"
                stats_size = cv2.getTextSize(stats_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
                stats_x = (width - stats_size[0]) // 2
                
                cv2.putText(image, stats_text, (stats_x, stats_y + 40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ğŸ” ì‹¤ì‹œê°„ í”¼ë“œë°± (ìš´ë™ë³„ êµ¬ì²´ì  ì¡°ì–¸)
        if analysis_result.get('violations') and pose_quality == "bad":
            feedback_y = height - 200
            cv2.putText(image, "ADJUSTMENTS NEEDED:", (30, feedback_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            for i, violation in enumerate(analysis_result['violations'][:2]):
                joint = violation['joint'].replace('_', ' ').title()
                feedback_text = f"â€¢ {joint} Position"
                cv2.putText(image, feedback_text, (30, feedback_y + 30 + i*25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # âŒ¨ï¸ ì¡°ì‘ ê°€ì´ë“œ
        guide_text = "Q: Quit  |  R: Reset Stats  |  S: Screenshot"
        cv2.putText(image, guide_text, (30, height - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return image
    
    def run_analysis(self, camera_id: int = 0):
        """ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰"""
        if not self.init_success:
            print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ {camera_id} ì—´ê¸° ì‹¤íŒ¨")
            print("ğŸ’¡ ë‹¤ë¥¸ ì¹´ë©”ë¼ IDë¥¼ ì‹œë„í•´ë³´ì„¸ìš”: --camera 1")
            return False
        
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        print("\n" + "="*60)
        print("ğŸ‹ï¸ BLAZE - ì‹¤ì‹œê°„ ìš´ë™ ìì„¸ ë¶„ì„ ì‹œìŠ¤í…œ")
        print("="*60)
        print("âœ¨ ê¸°ëŠ¥:")
        print("  â€¢ ìë™ ìš´ë™ ë¶„ë¥˜ (ìŠ¤ì¿¼íŠ¸, í‘¸ì‹œì—…, ë²¤ì¹˜í”„ë ˆìŠ¤, ë°ë“œë¦¬í”„íŠ¸, í’€ì—…)")
        print("  â€¢ ì‹¤ì‹œê°„ ìì„¸ ë¶„ì„ (Good/Bad)")
        print("  â€¢ ìŠ¤ë§ˆíŠ¸ í”¼ë“œë°± ì‹œìŠ¤í…œ")
        print("  â€¢ ì„±ê³¼ ì¶”ì ")
        print("\nâŒ¨ï¸ ì¡°ì‘ë²•:")
        print("  Q: ì¢…ë£Œ  |  R: í†µê³„ ë¦¬ì…‹  |  S: ìŠ¤í¬ë¦°ìƒ· ì €ì¥")
        print("="*60)
        
        if not self.model_loaded:
            print("\nâŒ ê²½ê³ : ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”:")
            print("python main.py --mode train")
            print("\nê·¸ë˜ë„ ìì„¸ ë¶„ì„ì€ ê°€ëŠ¥í•˜ì§€ë§Œ ìš´ë™ì„ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ ì¹´ë©”ë¼ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ëª¨ë“œ)
                frame = cv2.flip(frame, 1)
                
                # MediaPipe ì²˜ë¦¬
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = self.pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                    self.mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style())
                    
                    # 1ë‹¨ê³„: ìš´ë™ ë¶„ë¥˜
                    exercise, class_conf = self.classify_current_exercise(frame)
                    
                    # 2ë‹¨ê³„: ìì„¸ ë¶„ì„
                    pose_quality, analysis_result = self.analyze_pose_quality(results.pose_landmarks.landmark)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    if pose_quality == 'good':
                        self.good_count += 1
                    elif pose_quality == 'bad':
                        self.bad_count += 1
                    
                    # 3ë‹¨ê³„: ë¹„ì£¼ì–¼ í”¼ë“œë°±
                    frame = self.draw_enhanced_feedback(
                        frame, exercise, pose_quality, class_conf, self.pose_confidence, analysis_result
                    )
                
                else:
                    # í¬ì¦ˆ ë¯¸ê°ì§€
                    cv2.putText(frame, "STAND IN FRONT OF CAMERA", 
                               (frame.shape[1]//2 - 200, frame.shape[0]//2), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                
                # í™”ë©´ ì¶œë ¥
                cv2.imshow('ğŸ‹ï¸ BLAZE - Exercise Analysis', frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    # í†µê³„ ë¦¬ì…‹
                    self.good_count = 0
                    self.bad_count = 0
                    self.exercise_history.clear()
                    self.pose_history.clear()
                    self.current_exercise = "detecting..."
                    print("ğŸ“Š í†µê³„ ë¦¬ì…‹ ì™„ë£Œ")
                elif key == ord('s'):
                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # ìŠ¤í¬ë¦°ìƒ· í´ë” í™•ì¸/ìƒì„±
                    screenshot_dir = "outputs/screenshots"
                    os.makedirs(screenshot_dir, exist_ok=True)
                    
                    filename = f"{screenshot_dir}/blaze_screenshot_{timestamp}.jpg"
                    cv2.imwrite(filename, frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            import shutil
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
            
            # ìµœì¢… ë¦¬í¬íŠ¸
            total = self.good_count + self.bad_count
            if total > 0:
                print(f"\nğŸ“Š ì„¸ì…˜ ì™„ë£Œ!")
                print(f"  ì´ ë¶„ì„: {total} í”„ë ˆì„")
                print(f"  ì„±ê³µ: {self.good_count} ({self.good_count/total:.1%})")
                print(f"  ê°œì„  í•„ìš”: {self.bad_count} ({self.bad_count/total:.1%})")
                print("ğŸ¯ ê³„ì† ì—°ìŠµí•´ì„œ í¼ì„ ì™„ì„±í•˜ì„¸ìš”!")
            
            return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ğŸ‹ï¸ BLAZE ì‹¤ì‹œê°„ ìš´ë™ ë¶„ì„')
    parser.add_argument('--camera', type=int, default=0, help='ì¹´ë©”ë¼ ID')
    parser.add_argument('--model', type=str, default='models/exercise_classifier.pkl',
                       help='ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    analyzer = SimplifiedRealTimeAnalyzer(args.model)
    analyzer.run_analysis(args.camera)

if __name__ == "__main__":
    main()