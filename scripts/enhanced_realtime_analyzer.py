"""
í–¥ìƒëœ ì‹¤ì‹œê°„ ìš´ë™ ë¶„ì„ê¸° - 5ì¢…ëª© ì™„ì „ ì§€ì› (ìµœì¢… ì™„ì„±ë³¸)
ìŠ¤ì¿¼íŠ¸, í‘¸ì‹œì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…
- ë·° íƒ€ì… ìë™ ê°ì§€ (ì¸¡ë©´/ì •ë©´/í›„ë©´)
- ìš´ë™ë³„ ë§ì¶¤ ê°ë„ ê¸°ì¤€
- ê°•í™”ëœ ì‹œê°ì  í”¼ë“œë°± (ì´ˆë¡/ë¹¨ê°• í™”ë©´)
- ì™„í™”ëœ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ê¸°ë°˜ ì•ˆì •í™”
"""

import cv2
import numpy as np
import mediapipe as mp
import time
from collections import deque
import json
from typing import Dict, List, Tuple, Optional
import argparse
import tempfile
import os
import sys
from pathlib import Path

def import_modules():
    """í•„ìš”í•œ ëª¨ë“ˆë“¤ import"""
    try:
        from exercise_classifier import ExerciseClassificationModel
        from enhanced_pose_analysis import EnhancedExerciseClassifier, AdaptivePostProcessor
        return ExerciseClassificationModel, EnhancedExerciseClassifier, AdaptivePostProcessor
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")
        print("í•„ìš”í•œ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("  - exercise_classifier.py")
        print("  - enhanced_pose_analysis.py")
        return None, None, None

class Enhanced5ExerciseRealTimeAnalyzer:
    """í–¥ìƒëœ 5ì¢…ëª© ì‹¤ì‹œê°„ ë¶„ì„ê¸° (ì™„í™”ëœ ë²„ì „)"""
    
    def __init__(self, model_path: str = "models/exercise_classifier.pkl"):
        # ëª¨ë“ˆ import
        ExerciseClassificationModel, EnhancedExerciseClassifier, AdaptivePostProcessor = import_modules()
        if not all([ExerciseClassificationModel, EnhancedExerciseClassifier, AdaptivePostProcessor]):
            self.init_success = False
            return
        
        # MediaPipe ì´ˆê¸°í™”
        try:
            self.mp_pose = mp.solutions.pose
            self.pose = self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=1,
                enable_segmentation=False,
                min_detection_confidence=0.7,
                min_tracking_confidence=0.5
            )
            self.mp_drawing = mp.solutions.drawing_utils
            self.mp_drawing_styles = mp.solutions.drawing_styles
        except Exception as e:
            print(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.init_success = False
            return
        
        # ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ
        self.exercise_classifier = ExerciseClassificationModel()
        self.model_loaded = False
        
        if os.path.exists(model_path):
            self.model_loaded = self.exercise_classifier.load_model(model_path)
            if self.model_loaded:
                print(f"âœ… 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            else:
                print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {model_path}")
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
            print("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”: python main.py --mode train")
        
        # í–¥ìƒëœ ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™” (ì™„í™”ëœ ë²„ì „)
        try:
            self.pose_analyzer = EnhancedExerciseClassifier()
            # 5ì¢…ëª©ë³„ í›„ì²˜ë¦¬ê¸° (ë” ê´€ëŒ€í•œ ì„¤ì •)
            self.post_processors = {
                'squat': AdaptivePostProcessor(hysteresis_threshold=0.4, ema_alpha=0.3),      # ë” ê´€ëŒ€
                'push_up': AdaptivePostProcessor(hysteresis_threshold=0.3, ema_alpha=0.25),   # ì™„í™”ë¨
                'deadlift': AdaptivePostProcessor(hysteresis_threshold=0.5, ema_alpha=0.35),  # ê°€ì¥ ê´€ëŒ€
                'bench_press': AdaptivePostProcessor(hysteresis_threshold=0.35, ema_alpha=0.28),
                'pull_up': AdaptivePostProcessor(hysteresis_threshold=0.4, ema_alpha=0.32)
            }
        except Exception as e:
            print(f"âŒ ìì„¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.init_success = False
            return
        
        # 5ì¢…ëª© ì§€ì›
        self.available_exercises = ['squat', 'push_up', 'deadlift', 'bench_press', 'pull_up']
        self.current_exercise = "detecting..."
        self.current_pose_quality = "unknown"
        self.current_view_type = "unknown"
        self.classification_confidence = 0.0
        self.pose_confidence = 0.0
        
        # ì•ˆì •í™”ë¥¼ ìœ„í•œ íˆìŠ¤í† ë¦¬
        self.exercise_history = deque(maxlen=15)  # ìš´ë™ ë¶„ë¥˜ ì•ˆì •í™”
        self.pose_history = deque(maxlen=8)       # ìì„¸ ë¶„ì„ ì•ˆì •í™”
        
        # íƒ€ì´ë° ì œì–´
        self.last_classification_time = 0
        self.classification_interval = 3.0  # 3ì´ˆë§ˆë‹¤ ìš´ë™ ë¶„ë¥˜
        self.last_feedback_time = 0
        self.feedback_interval = 1.5  # 1.5ì´ˆë§ˆë‹¤ í”¼ë“œë°± ì—…ë°ì´íŠ¸
        
        # 5ì¢…ëª© í†µê³„
        self.session_stats = {
            'good_count': 0,
            'bad_count': 0,
            'total_frames': 0,
            'view_distribution': {'side_view': 0, 'front_view': 0, 'back_view': 0},
            'exercise_distribution': {ex: 0 for ex in self.available_exercises}
        }
        
        # í”¼ë“œë°± ë©”ì‹œì§€ í
        self.feedback_messages = deque(maxlen=3)
        
        # ì„ì‹œ íŒŒì¼ ë””ë ‰í† ë¦¬
        self.temp_dir = tempfile.mkdtemp()
        
        # í™”ë©´ ìƒíƒœ (ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•¨)
        self.screen_state = "neutral"  # neutral, good, bad, detecting
        self.state_transition_frames = 0
        self.transition_duration = 10  # 10í”„ë ˆì„ ë™ì•ˆ ì „í™˜
        
        self.init_success = True
    
    def classify_current_exercise(self, frame: np.ndarray) -> Tuple[str, float]:
        """í˜„ì¬ í”„ë ˆì„ì˜ 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜"""
        current_time = time.time()
        
        # ë¶„ë¥˜ ì£¼ê¸° ì œì–´ (3ì´ˆë§ˆë‹¤)
        if current_time - self.last_classification_time < self.classification_interval:
            return self.current_exercise, self.classification_confidence
        
        if not self.model_loaded:
            return "model_not_loaded", 0.0
        
        try:
            # ì„ì‹œ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            temp_path = os.path.join(self.temp_dir, "current_frame.jpg")
            cv2.imwrite(temp_path, frame)
            
            # ìš´ë™ ë¶„ë¥˜
            exercise, confidence = self.exercise_classifier.predict(temp_path)
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.exercise_history.append((exercise, confidence))
            
            # ì•ˆì •í™”: ìµœê·¼ ê²°ê³¼ë“¤ì˜ í•©ì˜
            if len(self.exercise_history) >= 5:
                # ì‹ ë¢°ë„ 0.4 ì´ìƒì¸ ì˜ˆì¸¡ë“¤ë§Œ ê³ ë ¤
                recent_predictions = [(ex, conf) for ex, conf in list(self.exercise_history)[-10:] 
                                    if conf > 0.4]
                
                if recent_predictions:
                    # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ê²°ì •
                    exercise_scores = {}
                    for ex, conf in recent_predictions:
                        if ex not in exercise_scores:
                            exercise_scores[ex] = []
                        exercise_scores[ex].append(conf)
                    
                    # ê° ìš´ë™ì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
                    avg_scores = {}
                    for ex, scores in exercise_scores.items():
                        avg_scores[ex] = np.mean(scores)
                    
                    # ê°€ì¥ ë†’ì€ í‰ê·  ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ìš´ë™ ì„ íƒ
                    if avg_scores:
                        best_exercise = max(avg_scores, key=avg_scores.get)
                        if avg_scores[best_exercise] > 0.5 and len(exercise_scores[best_exercise]) >= 3:
                            if best_exercise != self.current_exercise:
                                self.current_exercise = best_exercise
                                self.classification_confidence = avg_scores[best_exercise]
                                print(f"ğŸ¯ ìš´ë™ ê°ì§€: {best_exercise.upper()} (ì‹ ë¢°ë„: {avg_scores[best_exercise]:.2f})")
                                
                                # í†µê³„ ì—…ë°ì´íŠ¸
                                self.session_stats['exercise_distribution'][best_exercise] += 1
            
            self.last_classification_time = current_time
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_path):
                os.remove(temp_path)
            
            return self.current_exercise, self.classification_confidence
            
        except Exception as e:
            print(f"ìš´ë™ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return self.current_exercise, self.classification_confidence
    
    def analyze_pose_quality(self, landmarks) -> Tuple[str, Dict]:
        """í–¥ìƒëœ 5ì¢…ëª© ìì„¸ í’ˆì§ˆ ë¶„ì„"""
        if self.current_exercise in ["detecting...", "model_not_loaded", "unknown"]:
            return "waiting", {}
        
        try:
            # ëœë“œë§ˆí¬ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
            landmarks_dict = []
            for landmark in landmarks:
                landmarks_dict.append({
                    'x': landmark.x,
                    'y': landmark.y,
                    'z': landmark.z,
                    'visibility': landmark.visibility
                })
            
            # í–¥ìƒëœ ìì„¸ ë¶„ì„
            analysis = self.pose_analyzer.analyze_pose(landmarks_dict, self.current_exercise)
            if not analysis['valid']:
                return "invalid", {}
            
            # ë·° íƒ€ì… ì—…ë°ì´íŠ¸
            self.current_view_type = analysis.get('view_type', 'unknown')
            self.session_stats['view_distribution'][self.current_view_type] += 1
            
            # í•´ë‹¹ ìš´ë™ì˜ í›„ì²˜ë¦¬ê¸° ì„ íƒ
            post_processor = self.post_processors.get(self.current_exercise, 
                                                     self.post_processors['squat'])
            
            # í›„ì²˜ë¦¬ ì ìš©
            final_result = post_processor.process(analysis, self.current_exercise)
            pose_quality = final_result['final_classification']
            self.pose_confidence = final_result.get('confidence', 0.0)
            
            # ì•ˆì •í™”ëœ ìì„¸ í’ˆì§ˆ ê²°ì • (ë” ê´€ëŒ€í•˜ê²Œ)
            self.pose_history.append(pose_quality)
            
            if len(self.pose_history) >= 3:
                recent_poses = list(self.pose_history)[-5:]
                good_count = recent_poses.count('good')
                bad_count = recent_poses.count('bad')
                
                # ë‹¤ìˆ˜ê²° ì›ì¹™ + íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ (goodì— ë” ë§ì€ ê°€ì¤‘ì¹˜)
                if good_count >= bad_count * 1.2:  # goodì— ë” ë§ì€ ê°€ì¤‘ì¹˜ (ê¸°ì¡´ 1.5ì—ì„œ 1.2ë¡œ ì™„í™”)
                    self.current_pose_quality = 'good'
                else:
                    self.current_pose_quality = 'bad'
            else:
                self.current_pose_quality = pose_quality
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.session_stats['total_frames'] += 1
            if self.current_pose_quality == 'good':
                self.session_stats['good_count'] += 1
            elif self.current_pose_quality == 'bad':
                self.session_stats['bad_count'] += 1
            
            # í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±
            self.generate_feedback_messages(final_result)
            
            return self.current_pose_quality, final_result
            
        except Exception as e:
            print(f"ìì„¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return "error", {}
    
    def generate_feedback_messages(self, analysis_result: Dict):
        """5ì¢…ëª©ë³„ ë§ì¶¤ í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±"""
        current_time = time.time()
        
        # í”¼ë“œë°± ì£¼ê¸° ì œí•œ (1.5ì´ˆë§ˆë‹¤)
        if current_time - self.last_feedback_time < self.feedback_interval:
            return
        
        if not analysis_result.get('valid', False):
            return
        
        violations = analysis_result.get('violations', [])
        view_type = analysis_result.get('view_type', 'unknown')
        
        # 5ì¢…ëª©ë³„ ë§ì¶¤ ë©”ì‹œì§€
        exercise_messages = {
            'squat': {
                'good': ["ì™„ë²½í•œ ìŠ¤ì¿¼íŠ¸!", "ê¹Šì´ê°€ í›Œë¥­í•´ìš”!", "ë¬´ë¦ ê°ë„ ì™„ë²½!", "ìì„¸ ìœ ì§€ ì˜í•˜ê³  ìˆì–´ìš”!"],
                'bad': {
                    'knee': "ë¬´ë¦ì´ ë°œëì„ ë„˜ì§€ ì•Šê²Œ ì£¼ì˜í•˜ì„¸ìš”",
                    'hip': "ì—‰ë©ì´ë¥¼ ë” ë’¤ë¡œ ë¹¼ì„¸ìš”",
                    'back': "ë“±ì„ ê³§ê²Œ í´ì„¸ìš”",
                    'depth': "ë” ê¹Šì´ ì•‰ì•„ë³´ì„¸ìš”"
                }
            },
            'push_up': {
                'good': ["ì™„ë²½í•œ í‘¸ì‹œì—…!", "ëª¸ì´ ì¼ì§ì„ ì´ì—ìš”!", "íŒ”ê¿ˆì¹˜ ê°ë„ ì¢‹ì•„ìš”!", "ì½”ì–´ê°€ ì•ˆì •ì !"],
                'bad': {
                    'elbow': "íŒ”ê¿ˆì¹˜ë¥¼ ëª¸ì— ë” ê°€ê¹ê²Œ",
                    'body_line': "ëª¸ì„ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”",
                    'hip': "ì—‰ë©ì´ê°€ ë„ˆë¬´ ë†’ì•„ìš”",
                    'depth': "ê°€ìŠ´ì„ ë°”ë‹¥ì— ë” ê°€ê¹ê²Œ"
                }
            },
            'deadlift': {
                'good': ["ì™„ë²½í•œ ë°ë“œë¦¬í”„íŠ¸!", "ë“±ì´ ê³§ê³  ì¢‹ì•„ìš”!", "ë¬´ë¦ ìœ„ì¹˜ ì™„ë²½!", "ì—‰ë©ì´ íŒì§€ í›Œë¥­!"],
                'bad': {
                    'back': "ë“±ì„ ê³§ê²Œ í´ì„¸ìš” - ê°€ì¥ ì¤‘ìš”!",
                    'knee': "ë¬´ë¦ì„ ì•½ê°„ êµ¬ë¶€ë¦¬ì„¸ìš”",
                    'hip': "ì—‰ë©ì´ë¥¼ ë’¤ë¡œ ë” ë¹¼ì„¸ìš”",
                    'chest': "ê°€ìŠ´ì„ í´ê³  ì–´ê¹¨ë¥¼ ë’¤ë¡œ"
                }
            },
            'bench_press': {
                'good': ["ì™„ë²½í•œ ë²¤ì¹˜í”„ë ˆìŠ¤!", "íŒ”ê¿ˆì¹˜ ê°ë„ ìµœì !", "ì–´ê¹¨ ì•ˆì •ì !", "ê°€ë™ë²”ìœ„ í›Œë¥­!"],
                'bad': {
                    'elbow': "íŒ”ê¿ˆì¹˜ ê°ë„ë¥¼ ì¡°ì •í•˜ì„¸ìš”",
                    'shoulder': "ì–´ê¹¨ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€",
                    'arch': "ìì—°ìŠ¤ëŸ¬ìš´ ë“± ì•„ì¹˜ ìœ ì§€",
                    'path': "ë°”ë²¨ ê²½ë¡œë¥¼ ì¼ì •í•˜ê²Œ"
                }
            },
            'pull_up': {
                'good': ["ì™„ë²½í•œ í’€ì—…!", "ê´‘ë°°ê·¼ í™œì„±í™” ì¢‹ìŒ!", "í„±ì´ ë°” ìœ„ë¡œ!", "ëª¸ì´ ì•ˆì •ì !"],
                'bad': {
                    'elbow': "íŒ”ê¿ˆì¹˜ë¥¼ ì™„ì „íˆ í´ì„¸ìš”",
                    'shoulder': "ì–´ê¹¨ë¥¼ ì•„ë˜ë¡œ ë‹¹ê¸°ì„¸ìš”",
                    'body': "ëª¸ì˜ í”ë“¤ë¦¼ì„ ì¤„ì´ì„¸ìš”",
                    'range': "í’€ ë ˆì¸ì§€ë¡œ ë™ì‘í•˜ì„¸ìš”"
                }
            }
        }
        
        # ë©”ì‹œì§€ ìƒì„±
        if len(violations) == 0:
            # ì¢‹ì€ ìì„¸
            good_messages = exercise_messages.get(self.current_exercise, {}).get('good', ["ì¢‹ì€ ìì„¸!"])
            import random
            message = random.choice(good_messages)
            self.feedback_messages.append(('good', message, view_type))
        else:
            # ë‚˜ìœ ìì„¸ - ê°€ì¥ ì¤‘ìš”í•œ ìœ„ë°˜ì‚¬í•­ë§Œ ì„ íƒ
            bad_messages = exercise_messages.get(self.current_exercise, {}).get('bad', {})
            
            # ê°€ì¤‘ì¹˜ê°€ ë†’ì€ ìœ„ë°˜ì‚¬í•­ ìš°ì„ 
            violations.sort(key=lambda x: x.get('weight', 1.0), reverse=True)
            
            for violation in violations[:2]:  # ìµœëŒ€ 2ê°œë§Œ
                joint = violation['joint']
                
                # ê´€ì ˆëª…ì„ ë©”ì‹œì§€ í‚¤ë¡œ ë§¤í•‘
                message_key = self.map_joint_to_message_key(joint)
                message = bad_messages.get(message_key, f"{joint} ìì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”")
                
                self.feedback_messages.append(('bad', message, view_type))
        
        self.last_feedback_time = current_time
    
    def map_joint_to_message_key(self, joint: str) -> str:
        """ê´€ì ˆëª…ì„ ë©”ì‹œì§€ í‚¤ë¡œ ë§¤í•‘ (5ì¢…ëª© ì§€ì›)"""
        mapping = {
            'left_knee': 'knee', 'right_knee': 'knee',
            'left_hip': 'hip', 'right_hip': 'hip',
            'left_elbow': 'elbow', 'right_elbow': 'elbow',
            'left_shoulder': 'shoulder', 'right_shoulder': 'shoulder',
            'back_straight': 'back', 'left_back': 'back', 'right_back': 'back',
            'body_line': 'body_line', 'spine_straight': 'back',
            'chest_up': 'chest', 'back_arch': 'arch',
            'grip_symmetry': 'grip', 'lat_engagement': 'lat',
            'core_stability': 'body', 'body_straight': 'body'
        }
        return mapping.get(joint, joint.split('_')[0])
    
    def update_screen_state(self, target_state: str):
        """í™”ë©´ ìƒíƒœ ë¶€ë“œëŸ½ê²Œ ì „í™˜"""
        if target_state != self.screen_state:
            self.screen_state = target_state
            self.state_transition_frames = 0
        
        if self.state_transition_frames < self.transition_duration:
            self.state_transition_frames += 1
    
    def get_border_color(self) -> Tuple[int, int, int]:
        """í˜„ì¬ ìƒíƒœì— ë”°ë¥¸ í…Œë‘ë¦¬ ìƒ‰ìƒ ê³„ì‚°"""
        colors = {
            'good': (0, 255, 0),      # ì´ˆë¡ìƒ‰
            'bad': (0, 0, 255),       # ë¹¨ê°„ìƒ‰
            'detecting': (255, 255, 0), # ë…¸ë€ìƒ‰
            'neutral': (128, 128, 128)  # íšŒìƒ‰
        }
        
        base_color = colors.get(self.screen_state, colors['neutral'])
        
        # ì „í™˜ íš¨ê³¼ ì ìš©
        if self.state_transition_frames < self.transition_duration:
            # ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•œ ì•ŒíŒŒ ë¸”ë Œë”©
            alpha = self.state_transition_frames / self.transition_duration
            neutral_color = colors['neutral']
            
            blended_color = (
                int(neutral_color[0] * (1 - alpha) + base_color[0] * alpha),
                int(neutral_color[1] * (1 - alpha) + base_color[1] * alpha),
                int(neutral_color[2] * (1 - alpha) + base_color[2] * alpha)
            )
            return blended_color
        
        return base_color
    
    def draw_enhanced_feedback(self, image: np.ndarray) -> np.ndarray:
        """5ì¢…ëª© ê°•í™”ëœ ì‹œê°ì  í”¼ë“œë°±"""
        height, width = image.shape[:2]
        
        # í˜„ì¬ ìƒíƒœ ê²°ì •
        if self.current_exercise in ["detecting...", "model_not_loaded"]:
            target_state = "detecting"
            main_status = "ìš´ë™ì„ ê°ì§€í•˜ëŠ” ì¤‘..."
        elif self.current_pose_quality == "good":
            target_state = "good"
            main_status = "ì™„ë²½í•œ ìì„¸! ğŸ‘"
        elif self.current_pose_quality == "bad":
            target_state = "bad"
            main_status = "ìì„¸ë¥¼ êµì •í•˜ì„¸ìš” âš ï¸"
        else:
            target_state = "neutral"
            main_status = "ë¶„ì„ ì¤‘..."
        
        # í™”ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.update_screen_state(target_state)
        border_color = self.get_border_color()
        
        # ğŸ¯ í™”ë©´ ì „ì²´ì— ìƒ‰ìƒ ì˜¤ë²„ë ˆì´ (íˆ¬ëª…ë„ ì ìš©)
        if target_state in ['good', 'bad']:
            overlay = image.copy()
            cv2.rectangle(overlay, (0, 0), (width, height), border_color, -1)
            cv2.addWeighted(overlay, 0.1, image, 0.9, 0, image)
        
        # ğŸ¯ ë‘êº¼ìš´ í…Œë‘ë¦¬
        border_thickness = 25
        cv2.rectangle(image, (0, 0), (width, height), border_color, border_thickness)
        
        # ğŸ¯ ìƒë‹¨ ì •ë³´ íŒ¨ë„ (ë°˜íˆ¬ëª…)
        panel_height = 160
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (width, panel_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.8, image, 0.2, 0, image)
        
        # 5ì¢…ëª© ìš´ë™ ì¢…ëª© ë° ë·° íƒ€ì… í‘œì‹œ
        if self.current_exercise not in ["detecting...", "model_not_loaded"]:
            exercise_emoji = {
                'squat': 'ğŸ‹ï¸â€â™€ï¸',
                'push_up': 'ğŸ’ª',
                'deadlift': 'ğŸ‹ï¸â€â™‚ï¸',
                'bench_press': 'ğŸ”¥',
                'pull_up': 'ğŸ’¯'
            }
            
            exercise_text = f"{exercise_emoji.get(self.current_exercise, 'ğŸ‹ï¸')} {self.current_exercise.upper().replace('_', ' ')}"
            cv2.putText(image, exercise_text, (30, 45), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            
            # ë·° íƒ€ì…ê³¼ ì‹ ë¢°ë„
            info_text = f"ğŸ“¹ {self.current_view_type.replace('_', ' ').title()} | ì‹ ë¢°ë„: {self.classification_confidence:.0%}"
            cv2.putText(image, info_text, (30, 80), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)
            
            # ìì„¸ ì‹ ë¢°ë„
            pose_text = f"ìì„¸ ì ìˆ˜: {self.pose_confidence:.0%}"
            cv2.putText(image, pose_text, (30, 110), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)
            
            # ì§€ì› ì¢…ëª© í‘œì‹œ
            available_text = "ì§€ì› ì¢…ëª©: ìŠ¤ì¿¼íŠ¸ | í‘¸ì‹œì—… | ë°ë“œë¦¬í”„íŠ¸ | ë²¤ì¹˜í”„ë ˆìŠ¤ | í’€ì—…"
            cv2.putText(image, available_text, (30, 135), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        # ğŸ¯ ì¤‘ì•™ ìƒíƒœ ë©”ì‹œì§€ (í¬ê³  êµµê²Œ)
        status_size = cv2.getTextSize(main_status, cv2.FONT_HERSHEY_SIMPLEX, 1.8, 4)[0]
        status_x = (width - status_size[0]) // 2
        status_y = height // 2 - 80
        
        # ìƒíƒœ ë©”ì‹œì§€ ë°°ê²½
        padding = 30
        cv2.rectangle(image, 
                     (status_x - padding, status_y - 60), 
                     (status_x + status_size[0] + padding, status_y + 20), 
                     (0, 0, 0), -1)
        
        # í…Œë‘ë¦¬ ì¶”ê°€
        cv2.rectangle(image, 
                     (status_x - padding, status_y - 60), 
                     (status_x + status_size[0] + padding, status_y + 20), 
                     border_color, 3)
        
        cv2.putText(image, main_status, (status_x, status_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.8, border_color, 4)
        
        # ğŸ¯ ì‹¤ì‹œê°„ í”¼ë“œë°± ë©”ì‹œì§€ë“¤
        if self.feedback_messages:
            feedback_y = height // 2 + 40
            for i, (msg_type, message, view) in enumerate(list(self.feedback_messages)[-2:]):
                msg_color = (0, 255, 255) if msg_type == 'bad' else (0, 255, 0)
                
                # ë©”ì‹œì§€ ë°°ê²½
                msg_size = cv2.getTextSize(message, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
                msg_x = (width - msg_size[0]) // 2
                
                cv2.rectangle(image, 
                             (msg_x - 20, feedback_y + i*35 - 25), 
                             (msg_x + msg_size[0] + 20, feedback_y + i*35 + 10), 
                             (0, 0, 0), -1)
                
                cv2.putText(image, message, (msg_x, feedback_y + i*35), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, msg_color, 2)
        
        # ğŸ“Š í•˜ë‹¨ í†µê³„ íŒ¨ë„
        if self.current_exercise not in ["detecting...", "model_not_loaded"]:
            stats_y = height - 120
            cv2.rectangle(image, (0, stats_y), (width, height), (0, 0, 0), -1)
            
            # ì„¸ì…˜ í†µê³„
            total_analyzed = self.session_stats['good_count'] + self.session_stats['bad_count']
            if total_analyzed > 0:
                success_rate = self.session_stats['good_count'] / total_analyzed
                
                stats_text = f"ğŸ“ˆ ì„¸ì…˜ í†µê³„: ì´ {total_analyzed}í”„ë ˆì„ | ì„±ê³µë¥  {success_rate:.1%} | Good: {self.session_stats['good_count']} | Bad: {self.session_stats['bad_count']}"
                
                # í†µê³„ í…ìŠ¤íŠ¸ í¬ê¸°ì— ë§ì¶° ìœ„ì¹˜ ì¡°ì •
                stats_size = cv2.getTextSize(stats_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                stats_x = max(10, (width - stats_size[0]) // 2)
                
                cv2.putText(image, stats_text, (stats_x, stats_y + 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ìš´ë™ë³„ ê°ì§€ íšŸìˆ˜
                exercise_stats = []
                for ex, count in self.session_stats['exercise_distribution'].items():
                    if count > 0:
                        exercise_stats.append(f"{ex.upper()}: {count}")
                
                if exercise_stats:
                    exercise_text = "ğŸ‹ï¸ ê°ì§€ëœ ìš´ë™: " + " | ".join(exercise_stats[:3])  # ìµœëŒ€ 3ê°œë§Œ
                    cv2.putText(image, exercise_text, (10, stats_y + 55), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
                
                # ì„±ê³µë¥  ì§„í–‰ ë°”
                bar_width = width - 60
                bar_height = 15
                bar_x = 30
                bar_y = stats_y + 75
                
                # ë°°ê²½ ë°”
                cv2.rectangle(image, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (100, 100, 100), -1)
                
                # ì„±ê³µë¥  ë°”
                success_width = int(bar_width * success_rate)
                bar_color = (0, 255, 0) if success_rate > 0.7 else (0, 255, 255) if success_rate > 0.4 else (0, 0, 255)
                cv2.rectangle(image, (bar_x, bar_y), (bar_x + success_width, bar_y + bar_height), bar_color, -1)
        
        # âŒ¨ï¸ ì¡°ì‘ ê°€ì´ë“œ (í™”ë©´ í•˜ë‹¨)
        guide_text = "ğŸ”´ Q: ì¢…ë£Œ  |  ğŸ”„ R: ë¦¬ì…‹  |  ğŸ“¸ S: ìŠ¤í¬ë¦°ìƒ·  |  ğŸ¯ C: ìš´ë™ ë³€ê²½  |  ğŸ†˜ H: ë„ì›€ë§"
        guide_size = cv2.getTextSize(guide_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
        guide_x = (width - guide_size[0]) // 2
        
        cv2.putText(image, guide_text, (guide_x, height - 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (180, 180, 180), 1)
        
        return image
    
    def show_exercise_selection_help(self):
        """ìš´ë™ ì„ íƒ ë„ì›€ë§ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ‹ï¸ BLAZE 5ì¢…ëª© ìš´ë™ ê°€ì´ë“œ")
        print("="*60)
        print("ğŸ“‹ ì§€ì›ë˜ëŠ” ìš´ë™:")
        print("  1ï¸âƒ£ SQUAT (ìŠ¤ì¿¼íŠ¸)")
        print("     - ìµœì  ë·°: ì¸¡ë©´")
        print("     - í•µì‹¬: ë¬´ë¦ ê°ë„, ì—‰ë©ì´ ë’¤ë¡œ, ë“± ê³§ê²Œ")
        print("\n  2ï¸âƒ£ PUSH_UP (í‘¸ì‹œì—…)")
        print("     - ìµœì  ë·°: ì¸¡ë©´")
        print("     - í•µì‹¬: ëª¸ ì¼ì§ì„ , íŒ”ê¿ˆì¹˜ ê°ë„")
        print("\n  3ï¸âƒ£ DEADLIFT (ë°ë“œë¦¬í”„íŠ¸)")
        print("     - ìµœì  ë·°: ì¸¡ë©´")
        print("     - í•µì‹¬: ë“± ê³§ê²Œ(ê°€ì¥ ì¤‘ìš”), í™íŒì§€")
        print("\n  4ï¸âƒ£ BENCH_PRESS (ë²¤ì¹˜í”„ë ˆìŠ¤)")
        print("     - ìµœì  ë·°: ì¸¡ë©´")
        print("     - í•µì‹¬: íŒ”ê¿ˆì¹˜ ê°ë„, ì–´ê¹¨ ì•ˆì •ì„±")
        print("\n  5ï¸âƒ£ PULL_UP (í’€ì—…)")
        print("     - ìµœì  ë·°: ì¸¡ë©´")
        print("     - í•µì‹¬: í’€ ë ˆì¸ì§€, ì–´ê¹¨ ì•ˆì •ì„±")
        print("\nğŸ¯ ì´¬ì˜ íŒ:")
        print("  - ì „ì‹ ì´ í™”ë©´ì— ë“¤ì–´ì˜¤ë„ë¡")
        print("  - 2-3m ê±°ë¦¬ì—ì„œ ì´¬ì˜")
        print("  - ì¶©ë¶„í•œ ì¡°ëª…")
        print("  - ë‹¨ìˆœí•œ ë°°ê²½")
        print("="*60)
    
    def cycle_exercise(self):
        """ìš´ë™ ì¢…ëª© ìˆœí™˜ ë³€ê²½"""
        if self.current_exercise in self.available_exercises:
            current_idx = self.available_exercises.index(self.current_exercise)
        else:
            current_idx = -1
        
        next_idx = (current_idx + 1) % len(self.available_exercises)
        self.current_exercise = self.available_exercises[next_idx]
        
        # í•´ë‹¹ ìš´ë™ íˆìŠ¤í† ë¦¬ ë¦¬ì…‹
        if self.current_exercise in self.post_processors:
            self.post_processors[self.current_exercise].history.clear()
            self.post_processors[self.current_exercise].ema_value = None
            self.post_processors[self.current_exercise].last_state = 'good'
        
        print(f"ğŸ”„ ìš´ë™ ë³€ê²½: {self.current_exercise.upper()}")
        return self.current_exercise
    
    def run_analysis(self, camera_id: int = 0):
        """5ì¢…ëª© ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰"""
        if not self.init_success:
            print("âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return False
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            print(f"âŒ ì¹´ë©”ë¼ {camera_id} ì—´ê¸° ì‹¤íŒ¨")
            print("ğŸ’¡ ë‹¤ë¥¸ ì¹´ë©”ë¼ IDë¥¼ ì‹œë„í•´ë³´ì„¸ìš”: --camera 1")
            return False
        
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("\n" + "="*80)
        print("ğŸ‹ï¸ BLAZE - 5ì¢…ëª© í–¥ìƒëœ ì‹¤ì‹œê°„ ìš´ë™ ìì„¸ ë¶„ì„ ì‹œìŠ¤í…œ (ì™„í™”ëœ ë²„ì „)")
        print("="*80)
        print("âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥:")
        print("  â€¢ 5ì¢…ëª© ì™„ì „ ì§€ì› (ìŠ¤ì¿¼íŠ¸, í‘¸ì‹œì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…)")
        print("  â€¢ ë·° íƒ€ì… ìë™ ê°ì§€ (ì¸¡ë©´/ì •ë©´/í›„ë©´)")
        print("  â€¢ ìš´ë™ë³„ ë§ì¶¤ ê°ë„ ê¸°ì¤€ ë° ê°€ì¤‘ì¹˜")
        print("  â€¢ ì™„í™”ëœ ì ì‘í˜• íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ (ë” ê´€ëŒ€í•œ íŒì •)")
        print("  â€¢ ê°•í™”ëœ ì‹œê°ì  í”¼ë“œë°± (ì „ì²´ í™”ë©´ ìƒ‰ìƒ)")
        print("  â€¢ ì‹¤ì‹œê°„ ì„±ê³¼ ì¶”ì  ë° ë¶„ì„")
        print("\nğŸ¯ ì§€ì› ìš´ë™:")
        for i, exercise in enumerate(self.available_exercises, 1):
            emoji = {'squat': 'ğŸ‹ï¸â€â™€ï¸', 'push_up': 'ğŸ’ª', 'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 'bench_press': 'ğŸ”¥', 'pull_up': 'ğŸ’¯'}
            print(f"  {i}. {emoji.get(exercise, 'ğŸ‹ï¸')} {exercise.upper().replace('_', ' ')}")
        print("\nâŒ¨ï¸ ì¡°ì‘ë²•:")
        print("  Q: ì¢…ë£Œ  |  R: í†µê³„ ë¦¬ì…‹  |  S: ìŠ¤í¬ë¦°ìƒ·  |  C: ìš´ë™ ë³€ê²½  |  H: ë„ì›€ë§")
        print("="*80)
        
        if not self.model_loaded:
            print("\nâŒ ê²½ê³ : ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            print("ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”:")
            print("python main.py --mode train")
            print("\nìì„¸ ë¶„ì„ì€ ê°€ëŠ¥í•˜ì§€ë§Œ ìš´ë™ì„ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
            print("Cí‚¤ë¥¼ ëˆŒëŸ¬ ìš´ë™ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # FPS ì¸¡ì •ìš©
        fps_counter = deque(maxlen=30)
        frame_count = 0
        
        try:
            while True:
                start_time = time.time()
                
                ret, frame = cap.read()
                if not ret:
                    print("âŒ ì¹´ë©”ë¼ ì½ê¸° ì‹¤íŒ¨")
                    break
                
                # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ëª¨ë“œ)
                frame = cv2.flip(frame, 1)
                frame_count += 1
                
                # MediaPipe ì²˜ë¦¬
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = self.pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                    self.mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style())
                    
                    # 1ë‹¨ê³„: 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
                    if self.model_loaded:
                        exercise, class_conf = self.classify_current_exercise(frame)
                    else:
                        exercise, class_conf = self.current_exercise, 0.0
                    
                    # 2ë‹¨ê³„: í–¥ìƒëœ ìì„¸ ë¶„ì„
                    pose_quality, analysis_result = self.analyze_pose_quality(results.pose_landmarks.landmark)
                    
                    # 3ë‹¨ê³„: ê°•í™”ëœ ë¹„ì£¼ì–¼ í”¼ë“œë°±
                    frame = self.draw_enhanced_feedback(frame)
                
                else:
                    # í¬ì¦ˆ ë¯¸ê°ì§€
                    self.update_screen_state("neutral")
                    frame = self.draw_enhanced_feedback(frame)
                    
                    # í¬ì¦ˆ ë¯¸ê°ì§€ ë©”ì‹œì§€
                    cv2.putText(frame, "ì¹´ë©”ë¼ ì•ì— ì„œì„œ ì „ì‹ ì´ ë³´ì´ë„ë¡ í•´ì£¼ì„¸ìš”", 
                               (frame.shape[1]//2 - 300, frame.shape[0]//2), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                
                # FPS ê³„ì‚° ë° í‘œì‹œ
                end_time = time.time()
                fps = 1 / max(end_time - start_time, 0.001)
                fps_counter.append(fps)
                avg_fps = sum(fps_counter) / len(fps_counter)
                
                cv2.putText(frame, f"FPS: {avg_fps:.1f}", (frame.shape[1] - 120, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # í™”ë©´ ì¶œë ¥
                cv2.imshow('ğŸ‹ï¸ BLAZE - 5-Exercise Enhanced Analysis (Relaxed)', frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    # í†µê³„ ë¦¬ì…‹
                    self.session_stats = {
                        'good_count': 0, 'bad_count': 0, 'total_frames': 0,
                        'view_distribution': {'side_view': 0, 'front_view': 0, 'back_view': 0},
                        'exercise_distribution': {ex: 0 for ex in self.available_exercises}
                    }
                    self.exercise_history.clear()
                    self.pose_history.clear()
                    self.feedback_messages.clear()
                    for processor in self.post_processors.values():
                        processor.history.clear()
                        processor.ema_value = None
                        processor.last_state = 'good'
                    print("ğŸ“Š ì „ì²´ í†µê³„ ë° íˆìŠ¤í† ë¦¬ ë¦¬ì…‹ ì™„ë£Œ")
                    
                elif key == ord('s'):
                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    screenshot_dir = "outputs/screenshots"
                    os.makedirs(screenshot_dir, exist_ok=True)
                    
                    filename = f"{screenshot_dir}/blaze_5exercise_{self.current_exercise}_{timestamp}.jpg"
                    cv2.imwrite(filename, frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
                    
                elif key == ord('c'):
                    # ìš´ë™ ìˆ˜ë™ ë³€ê²½
                    self.cycle_exercise()
                    
                elif key == ord('h'):
                    # ë„ì›€ë§ í‘œì‹œ
                    self.show_exercise_selection_help()
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ì ì¤‘ë‹¨")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            import shutil
            if os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir)
            
            # ìµœì¢… ì„¸ì…˜ ë¦¬í¬íŠ¸
            self.print_session_report()
            
            return True
    
    def print_session_report(self):
        """5ì¢…ëª© ì„¸ì…˜ ì™„ë£Œ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        total_analyzed = self.session_stats['good_count'] + self.session_stats['bad_count']
        
        print(f"\n" + "="*70)
        print(f"ğŸ“Š BLAZE 5ì¢…ëª© ì„¸ì…˜ ì™„ë£Œ ë¦¬í¬íŠ¸ (ì™„í™”ëœ ë²„ì „)")
        print(f"="*70)
        
        if total_analyzed > 0:
            success_rate = self.session_stats['good_count'] / total_analyzed
            
            print(f"ğŸ¯ ì´ ë¶„ì„ í”„ë ˆì„: {total_analyzed:,}ê°œ")
            print(f"âœ… ì¢‹ì€ ìì„¸: {self.session_stats['good_count']:,}ê°œ ({success_rate:.1%})")
            print(f"âš ï¸ ê°œì„  í•„ìš”: {self.session_stats['bad_count']:,}ê°œ ({1-success_rate:.1%})")
            
            # ë·° ë¶„í¬
            print(f"\nğŸ“¹ ì´¬ì˜ ê°ë„ ë¶„í¬:")
            total_views = sum(self.session_stats['view_distribution'].values())
            for view, count in self.session_stats['view_distribution'].items():
                if total_views > 0:
                    percentage = count / total_views * 100
                    print(f"  {view.replace('_', ' ').title()}: {count:,}ê°œ ({percentage:.1f}%)")
            
            # 5ì¢…ëª© ìš´ë™ ë¶„í¬ (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
            if any(count > 0 for count in self.session_stats['exercise_distribution'].values()):
                print(f"\nğŸ‹ï¸ ê°ì§€ëœ ìš´ë™ ë¶„í¬:")
                exercise_emoji = {
                    'squat': 'ğŸ‹ï¸â€â™€ï¸', 'push_up': 'ğŸ’ª', 'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 
                    'bench_press': 'ğŸ”¥', 'pull_up': 'ğŸ’¯'
                }
                for exercise, count in self.session_stats['exercise_distribution'].items():
                    if count > 0:
                        emoji = exercise_emoji.get(exercise, 'ğŸ‹ï¸')
                        print(f"  {emoji} {exercise.replace('_', ' ').title()}: {count}íšŒ ê°ì§€")
            
            # ì„±ê³¼ í‰ê°€ (ì™„í™”ëœ ê¸°ì¤€)
            print(f"\nğŸ† ì„±ê³¼ í‰ê°€ (ì™„í™”ëœ ê¸°ì¤€):")
            if success_rate >= 0.6:  # ê¸°ì¡´ 0.8ì—ì„œ 0.6ìœ¼ë¡œ ì™„í™”
                print(f"  ğŸ¥‡ í›Œë¥­í•¨! ìì„¸ê°€ ë§¤ìš° ì•ˆì •ì ì…ë‹ˆë‹¤.")
                print(f"  ğŸ’¡ íŒ: ë‹¤ë¥¸ ìš´ë™ë„ ë„ì „í•´ë³´ì„¸ìš”!")
            elif success_rate >= 0.4:  # ê¸°ì¡´ 0.6ì—ì„œ 0.4ë¡œ ì™„í™”
                print(f"  ğŸ¥ˆ ì¢‹ìŒ! ì¡°ê¸ˆ ë” ì—°ìŠµí•˜ë©´ ì™„ë²½í•´ì§ˆ ê±°ì˜ˆìš”.")
                print(f"  ğŸ’¡ íŒ: ì¸¡ë©´ ë·°ì—ì„œ ì´¬ì˜í•˜ë©´ ë” ì •í™•í•©ë‹ˆë‹¤.")
            elif success_rate >= 0.2:  # ê¸°ì¡´ 0.4ì—ì„œ 0.2ë¡œ ì™„í™”
                print(f"  ğŸ¥‰ ë³´í†µ! ê¸°ë³¸ ìì„¸ë¥¼ ë” ì—°ìŠµí•´ë³´ì„¸ìš”.")
                print(f"  ğŸ’¡ íŒ: ì²œì²œíˆ ì •í™•í•œ ë™ì‘ë¶€í„° ìµí˜€ë‚˜ê°€ì„¸ìš”.")
            else:
                print(f"  ğŸ’ª í™”ì´íŒ…! ì²œì²œíˆ ì •í™•í•œ ìì„¸ë¶€í„° ìµí˜€ë‚˜ê°€ì„¸ìš”.")
                print(f"  ğŸ’¡ íŒ: Hí‚¤ë¥¼ ëˆŒëŸ¬ ìš´ë™ë³„ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print(f"ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"\nğŸ“ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ:")
        print(f"  1. ì„±ê³µë¥ ì´ ë‚®ì€ ìš´ë™ì€ ë” ë§ì€ ì—°ìŠµì´ í•„ìš”")
        print(f"  2. ì¸¡ë©´ ë·°ì—ì„œ ì´¬ì˜í•˜ë©´ ê°€ì¥ ì •í™•í•œ ë¶„ì„ ê°€ëŠ¥")
        print(f"  3. ê° ìš´ë™ì˜ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ê¸°ì–µí•˜ë©° ì—°ìŠµ")
        print(f"  4. ì •ê¸°ì ì¸ ìì„¸ ì²´í¬ë¡œ ë¶€ìƒ ì˜ˆë°©")
        print(f"  5. ì™„í™”ëœ ê¸°ì¤€ìœ¼ë¡œ ë” ë§ì€ Good íŒì • ë°›ê¸°!")
        print(f"="*70)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ğŸ‹ï¸ BLAZE 5ì¢…ëª© í–¥ìƒëœ ì‹¤ì‹œê°„ ìš´ë™ ë¶„ì„ (ì™„í™”ëœ ë²„ì „)')
    parser.add_argument('--camera', type=int, default=0, help='ì¹´ë©”ë¼ ID')
    parser.add_argument('--model', type=str, default='models/exercise_classifier.pkl',
                       help='ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    analyzer = Enhanced5ExerciseRealTimeAnalyzer(args.model)
    analyzer.run_analysis(args.camera)

if __name__ == "__main__":
    main()