import cv2
import numpy as np
import mediapipe as mp
import time
from collections import deque
import json
from typing import Dict, List, Tuple, Optional
import argparse

class RealtimePoseAnalyzer:
    """ì‹¤ì‹œê°„ ìš´ë™ ìì„¸ ë¶„ì„ê¸° - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
    
    def __init__(self, exercise_type: str = 'squat'):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,  # ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë‚®ì€ ë³µì¡ë„ ì‚¬ìš©
            enable_segmentation=False,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        self.exercise_type = exercise_type
        
        # ğŸš€ í’€ì—…â†’ëŸ°ì§€ êµì²´ ìš´ë™ë³„ ê°ë„ ê¸°ì¤€ (ì™„í™”ë¨)
        self.exercise_thresholds = {
            'bench_press': [
                {'name': 'left_elbow', 'points': [11, 13, 15], 'range': (20, 180)},    # ì™„í™”ë¨
                {'name': 'right_elbow', 'points': [12, 14, 16], 'range': (20, 180)},   # ì™„í™”ë¨
                {'name': 'left_shoulder', 'points': [13, 11, 23], 'range': (20, 170)}, # ì™„í™”ë¨
                {'name': 'right_shoulder', 'points': [14, 12, 24], 'range': (20, 170)}, # ì™„í™”ë¨
            ],
            'deadlift': [
                {'name': 'left_knee', 'points': [23, 25, 27], 'range': (100, 180)},   # ì™„í™”ë¨
                {'name': 'right_knee', 'points': [24, 26, 28], 'range': (100, 180)},  # ì™„í™”ë¨
                {'name': 'left_hip', 'points': [11, 23, 25], 'range': (80, 180)},     # ì™„í™”ë¨
                {'name': 'right_hip', 'points': [12, 24, 26], 'range': (80, 180)},    # ì™„í™”ë¨
            ],
            'lunge': [  # ğŸš€ ìƒˆë¡œ ì¶”ê°€ëœ ëŸ°ì§€
                {'name': 'front_knee', 'points': [23, 25, 27], 'range': (70, 130)},   # ì•ë¬´ë¦ (ëŸ°ì§€ í•µì‹¬)
                {'name': 'back_knee', 'points': [24, 26, 28], 'range': (120, 180)},   # ë’·ë¬´ë¦ (ê±°ì˜ í´ì§)
                {'name': 'front_hip', 'points': [11, 23, 25], 'range': (70, 130)},    # ì• ì—‰ë©ì´
                {'name': 'torso_upright', 'points': [11, 23, 25], 'range': (160, 180)}, # ìƒì²´ ì§ë¦½
                {'name': 'front_ankle', 'points': [25, 27, 31], 'range': (80, 120)},  # ì•ë°œëª© ì•ˆì •ì„±
                {'name': 'back_hip_extension', 'points': [12, 24, 26], 'range': (140, 180)}, # ë’·ì—‰ë©ì´ ì‹ ì „
            ],
            'push_up': [
                {'name': 'left_elbow', 'points': [11, 13, 15], 'range': (20, 170)},   # ê¸°ì¡´ ìœ ì§€
                {'name': 'right_elbow', 'points': [12, 14, 16], 'range': (20, 170)},  # ê¸°ì¡´ ìœ ì§€
                {'name': 'left_hip', 'points': [11, 23, 25], 'range': (100, 180)},    # ê¸°ì¡´ ìœ ì§€
                {'name': 'right_hip', 'points': [12, 24, 26], 'range': (100, 180)},   # ê¸°ì¡´ ìœ ì§€
            ],
            'squat': [
                {'name': 'left_knee', 'points': [23, 25, 27], 'range': (40, 160)},    # ê¸°ì¡´ ìœ ì§€
                {'name': 'right_knee', 'points': [24, 26, 28], 'range': (40, 160)},   # ê¸°ì¡´ ìœ ì§€
                {'name': 'left_hip', 'points': [11, 23, 25], 'range': (40, 160)},     # ê¸°ì¡´ ìœ ì§€
                {'name': 'right_hip', 'points': [12, 24, 26], 'range': (40, 160)},    # ê¸°ì¡´ ìœ ì§€
            ]
        }
        
        # í›„ì²˜ë¦¬ ì„¤ì • (ì™„í™”ë¨)
        self.hysteresis_threshold = 0.4  # ê¸°ë³¸ê°’ ì™„í™”
        self.ema_alpha = 0.2
        self.window_size = 10
        
        # ìƒíƒœ ì¶”ì 
        self.history = deque(maxlen=self.window_size)
        self.ema_value = None
        self.last_state = 'good'
        self.state_counter = {'good': 0, 'bad': 0}
        
        # í”¼ë“œë°± ì‹œìŠ¤í…œ
        self.feedback_messages = deque(maxlen=5)
        self.last_feedback_time = 0
        
    def calculate_angle(self, p1: np.ndarray, p2: np.ndarray, p3: np.ndarray) -> float:
        """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
        try:
            v1 = p1 - p2
            v2 = p3 - p2
            
            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
            cos_angle = np.clip(cos_angle, -1.0, 1.0)
            angle = np.arccos(cos_angle)
            
            return np.degrees(angle)
        except:
            return 0.0
    
    def analyze_frame(self, landmarks) -> Dict:
        """í”„ë ˆì„ ë¶„ì„ - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
        if self.exercise_type not in self.exercise_thresholds:
            return {'valid': False, 'error': 'Unknown exercise type'}
        
        thresholds = self.exercise_thresholds[self.exercise_type]
        angles = {}
        violations = []
        
        for threshold in thresholds:
            try:
                p1_idx, p2_idx, p3_idx = threshold['points']
                min_angle, max_angle = threshold['range']
                
                # ê°€ì‹œì„± í™•ì¸ (ì™„í™”ë¨)
                if (landmarks[p1_idx].visibility < 0.4 or 
                    landmarks[p2_idx].visibility < 0.4 or 
                    landmarks[p3_idx].visibility < 0.4):
                    continue
                
                p1 = np.array([landmarks[p1_idx].x, landmarks[p1_idx].y])
                p2 = np.array([landmarks[p2_idx].x, landmarks[p2_idx].y])
                p3 = np.array([landmarks[p3_idx].x, landmarks[p3_idx].y])
                
                angle = self.calculate_angle(p1, p2, p3)
                angles[threshold['name']] = angle
                
                # í—ˆìš© ë²”ìœ„ í™•ì¸
                if not (min_angle <= angle <= max_angle):
                    violations.append({
                        'joint': threshold['name'],
                        'angle': angle,
                        'expected_range': (min_angle, max_angle)
                    })
                    
            except Exception as e:
                continue
        
        return {
            'valid': True,
            'angles': angles,
            'violations': violations,
            'violation_count': len(violations)
        }
    
    def apply_post_processing(self, analysis_result: Dict) -> Dict:
        """í›„ì²˜ë¦¬ ì ìš© (ì™„í™”ë¨)"""
        if not analysis_result['valid']:
            return analysis_result
        
        # ìœ„ë°˜ ë¹„ìœ¨ ê³„ì‚°
        total_angles = len(analysis_result['angles'])
        violation_count = analysis_result['violation_count']
        violation_ratio = violation_count / total_angles if total_angles > 0 else 0
        
        # EMA ì ìš©
        if self.ema_value is None:
            self.ema_value = violation_ratio
        else:
            self.ema_value = self.ema_alpha * violation_ratio + (1 - self.ema_alpha) * self.ema_value
        
        # íˆìŠ¤í† ë¦¬ ì¶”ê°€
        self.history.append(self.ema_value)
        
        # ì™„í™”ëœ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì ìš©
        exercise_thresholds = {
            'squat': 0.5,        # ê¸°ì¡´ ìœ ì§€
            'push_up': 0.8,      # ê¸°ì¡´ ìœ ì§€
            'deadlift': 0.6,     # ì™„í™”ë¨
            'bench_press': 0.7,  # ì™„í™”ë¨
            'lunge': 0.5,        # ìƒˆë¡œìš´ ëŸ°ì§€
        }
        
        threshold = exercise_thresholds.get(self.exercise_type, 0.4)
        
        if self.last_state == 'good':
            if self.ema_value > threshold:
                self.last_state = 'bad'
        else:
            if self.ema_value < threshold * 0.4:  # ë³µê·€ ê¸°ì¤€ë„ ì™„í™”
                self.last_state = 'good'
        
        # ìƒíƒœ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
        self.state_counter[self.last_state] += 1
        
        return {
            **analysis_result,
            'final_classification': self.last_state,
            'violation_ratio': violation_ratio,
            'smoothed_ratio': self.ema_value,
            'confidence': 1.0 - self.ema_value
        }
    
    def generate_feedback(self, analysis_result: Dict) -> str:
        """í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„± - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
        current_time = time.time()
        
        # í”¼ë“œë°± ì£¼ê¸° ì œí•œ (2ì´ˆë§ˆë‹¤)
        if current_time - self.last_feedback_time < 2.0:
            return ""
        
        if not analysis_result['valid']:
            return "í¬ì¦ˆë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        feedback = ""
        violations = analysis_result['violations']
        
        # ğŸš€ ìš´ë™ë³„ ë§ì¶¤ í”¼ë“œë°± ë©”ì‹œì§€
        exercise_feedback = {
            'squat': {
                'good': "ì™„ë²½í•œ ìŠ¤ì¿¼íŠ¸ ìì„¸ì…ë‹ˆë‹¤!",
                'bad_knee': "ë¬´ë¦ ê°ë„ë¥¼ ì¡°ì •í•˜ì„¸ìš”",
                'bad_hip': "ì—‰ë©ì´ë¥¼ ë” ë’¤ë¡œ ë¹¼ì„¸ìš”"
            },
            'push_up': {
                'good': "í›Œë¥­í•œ í‘¸ì‰¬ì—… í¼ì…ë‹ˆë‹¤!",
                'bad_elbow': "íŒ”ê¿ˆì¹˜ ê°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”",
                'bad_hip': "ëª¸ì„ ì¼ì§ì„ ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”"
            },
            'deadlift': {
                'good': "ì™„ë²½í•œ ë°ë“œë¦¬í”„íŠ¸ ìì„¸ì…ë‹ˆë‹¤!",
                'bad_knee': "ë¬´ë¦ì„ ì•½ê°„ êµ¬ë¶€ë¦¬ì„¸ìš”",
                'bad_hip': "ì—‰ë©ì´ë¥¼ ë’¤ë¡œ ë” ë¹¼ì„¸ìš”"
            },
            'bench_press': {
                'good': "ì™„ë²½í•œ ë²¤ì¹˜í”„ë ˆìŠ¤ì…ë‹ˆë‹¤!",
                'bad_elbow': "íŒ”ê¿ˆì¹˜ ê°ë„ë¥¼ ì¡°ì •í•˜ì„¸ìš”",
                'bad_shoulder': "ì–´ê¹¨ ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”"
            },
            'lunge': {  # ğŸš€ ìƒˆë¡œ ì¶”ê°€ëœ ëŸ°ì§€ í”¼ë“œë°±
                'good': "ì™„ë²½í•œ ëŸ°ì§€ ìì„¸ì…ë‹ˆë‹¤!",
                'bad_front_knee': "ì•ë¬´ë¦ì„ 90ë„ë¡œ êµ¬ë¶€ë¦¬ì„¸ìš”",
                'bad_back_knee': "ë’·ë¬´ë¦ì„ ë” í´ì„¸ìš”",
                'bad_torso': "ìƒì²´ë¥¼ ê³§ê²Œ ì„¸ìš°ì„¸ìš”",
                'bad_front_ankle': "ì•ë°œëª© ì•ˆì •ì„±ì„ ìœ ì§€í•˜ì„¸ìš”"
            }
        }
        
        if len(violations) == 0:
            feedback = exercise_feedback.get(self.exercise_type, {}).get('good', "ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤!")
        else:
            # ìš´ë™ë³„ íŠ¹í™” í”¼ë“œë°±
            for violation in violations[:2]:  # ìµœëŒ€ 2ê°œ í”¼ë“œë°±
                joint = violation['joint']
                
                if 'knee' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_knee', f"{joint} ê°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”") + ", "
                elif 'hip' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_hip', f"{joint} ê°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”") + ", "
                elif 'elbow' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_elbow', f"{joint} ê°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”") + ", "
                elif 'shoulder' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_shoulder', f"{joint} ê°ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”") + ", "
                elif 'torso' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_torso', f"{joint} ìì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”") + ", "
                elif 'ankle' in joint:
                    feedback += exercise_feedback.get(self.exercise_type, {}).get('bad_ankle', f"{joint} ì•ˆì •ì„±ì„ í™•ì¸í•˜ì„¸ìš”") + ", "
        
        self.last_feedback_time = current_time
        return feedback.rstrip(', ')
    
    def draw_pose_info(self, image: np.ndarray, analysis_result: Dict) -> np.ndarray:
        """ì´ë¯¸ì§€ì— í¬ì¦ˆ ì •ë³´ ê·¸ë¦¬ê¸° - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
        height, width = image.shape[:2]
        
        # ìš´ë™ ì´ëª¨ì§€
        exercise_emojis = {
            'squat': 'ğŸ‹ï¸â€â™€ï¸',
            'push_up': 'ğŸ’ª',
            'deadlift': 'ğŸ‹ï¸â€â™‚ï¸',
            'bench_press': 'ğŸ”¥',
            'lunge': 'ğŸš€'  # ìƒˆë¡œ ì¶”ê°€ëœ ëŸ°ì§€
        }
        
        # ìƒíƒœ í‘œì‹œ
        state = analysis_result.get('final_classification', 'unknown')
        color = (0, 255, 0) if state == 'good' else (0, 0, 255)
        
        # ìš´ë™ ì¢…ëª©ê³¼ ìƒíƒœ
        exercise_text = f"{exercise_emojis.get(self.exercise_type, 'ğŸ‹ï¸')} {self.exercise_type.upper()}: {state.upper()}"
        cv2.putText(image, exercise_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        
        # ì‹ ë¢°ë„ í‘œì‹œ
        confidence = analysis_result.get('confidence', 0)
        cv2.putText(image, f"Confidence: {confidence:.2f}", (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ê°ë„ ì •ë³´ í‘œì‹œ
        if 'angles' in analysis_result:
            y_offset = 110
            for joint, angle in analysis_result['angles'].items():
                cv2.putText(image, f"{joint}: {angle:.1f}Â°", (10, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                y_offset += 25
        
        # í”¼ë“œë°± ë©”ì‹œì§€ í‘œì‹œ
        feedback = self.generate_feedback(analysis_result)
        if feedback:
            self.feedback_messages.append(feedback)
        
        if self.feedback_messages:
            y_offset = height - 100
            for msg in list(self.feedback_messages)[-3:]:  # ìµœëŒ€ 3ê°œ ë©”ì‹œì§€
                cv2.putText(image, msg, (10, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
                y_offset += 30
        
        # ìš´ë™ ì¹´ìš´í„° í‘œì‹œ
        total_frames = self.state_counter['good'] + self.state_counter['bad']
        if total_frames > 0:
            good_ratio = self.state_counter['good'] / total_frames
            cv2.putText(image, f"Good Ratio: {good_ratio:.2f}", (width - 200, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return image
    
    def run_camera(self, camera_id: int = 0):
        """ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ë¶„ì„ - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
        cap = cv2.VideoCapture(camera_id)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        print(f"Starting real-time pose analysis for {self.exercise_type} (í’€ì—…â†’ëŸ°ì§€ êµì²´)")
        print("Press 'q' to quit, 'r' to reset counters, 's' to save screenshot")
        
        frame_count = 0
        fps_counter = deque(maxlen=30)
        
        try:
            while True:
                start_time = time.time()
                
                ret, frame = cap.read()
                if not ret:
                    print("Failed to read from camera")
                    break
                
                # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ëª¨ë“œ)
                frame = cv2.flip(frame, 1)
                
                # RGB ë³€í™˜
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # í¬ì¦ˆ ê²€ì¶œ
                results = self.pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                    self.mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style())
                    
                    # ìì„¸ ë¶„ì„
                    analysis = self.analyze_frame(results.pose_landmarks.landmark)
                    final_result = self.apply_post_processing(analysis)
                    
                    # ì •ë³´ í‘œì‹œ
                    frame = self.draw_pose_info(frame, final_result)
                else:
                    cv2.putText(frame, "No pose detected", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                
                # FPS ê³„ì‚°
                end_time = time.time()
                fps = 1 / (end_time - start_time)
                fps_counter.append(fps)
                avg_fps = sum(fps_counter) / len(fps_counter)
                
                cv2.putText(frame, f"FPS: {avg_fps:.1f}", (10, frame.shape[0] - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow(f'{self.exercise_type.replace("_", " ").title()} Pose Analysis', frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('r'):
                    self.state_counter = {'good': 0, 'bad': 0}
                    self.history.clear()
                    self.ema_value = None
                    self.last_state = 'good'
                    print("Counters reset")
                elif key == ord('s'):
                    filename = f"screenshot_{self.exercise_type}_{int(time.time())}.jpg"
                    cv2.imwrite(filename, frame)
                    print(f"Screenshot saved: {filename}")
                
                frame_count += 1
                
        except KeyboardInterrupt:
            print("\nStopping...")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            # ìµœì¢… í†µê³„ ì¶œë ¥
            total_frames = self.state_counter['good'] + self.state_counter['bad']
            if total_frames > 0:
                print(f"\n=== Final Statistics ({self.exercise_type}) ===")
                print(f"Total frames analyzed: {total_frames}")
                print(f"Good poses: {self.state_counter['good']} ({self.state_counter['good']/total_frames:.2%})")
                print(f"Bad poses: {self.state_counter['bad']} ({self.state_counter['bad']/total_frames:.2%})")
    
    def analyze_video(self, video_path: str, output_path: str = None):
        """ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
        cap = cv2.VideoCapture(video_path)
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"Analyzing video: {video_path}")
        print(f"Resolution: {width}x{height}, FPS: {fps}, Total frames: {total_frames}")
        
        # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_results = []
        frame_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # RGB ë³€í™˜
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # í¬ì¦ˆ ê²€ì¶œ
                results = self.pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
                    self.mp_drawing.draw_landmarks(
                        frame, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style())
                    
                    # ìì„¸ ë¶„ì„
                    analysis = self.analyze_frame(results.pose_landmarks.landmark)
                    final_result = self.apply_post_processing(analysis)
                    
                    # ì •ë³´ í‘œì‹œ
                    frame = self.draw_pose_info(frame, final_result)
                    
                    # ê²°ê³¼ ì €ì¥
                    frame_results.append({
                        'frame': frame_count,
                        'timestamp': frame_count / fps,
                        'classification': final_result.get('final_classification', 'unknown'),
                        'confidence': final_result.get('confidence', 0),
                        'angles': final_result.get('angles', {}),
                        'violations': final_result.get('violations', [])
                    })
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if frame_count % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    print(f"Progress: {progress:.1f}%")
                
                # ì¶œë ¥ ë¹„ë””ì˜¤ì— ì“°ê¸°
                if output_path:
                    out.write(frame)
                
                frame_count += 1
                
        except KeyboardInterrupt:
            print("\nStopping...")
        finally:
            cap.release()
            if output_path:
                out.release()
            
            # ê²°ê³¼ ì €ì¥
            if frame_results:
                result_file = video_path.replace('.mp4', f'_{self.exercise_type}_analysis.json')
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(frame_results, f, indent=2, ensure_ascii=False)
                
                # í†µê³„ ê³„ì‚°
                good_frames = sum(1 for r in frame_results if r['classification'] == 'good')
                bad_frames = len(frame_results) - good_frames
                
                print(f"\n=== Video Analysis Complete ({self.exercise_type}) ===")
                print(f"Results saved to: {result_file}")
                print(f"Total frames analyzed: {len(frame_results)}")
                print(f"Good poses: {good_frames} ({good_frames/len(frame_results):.2%})")
                print(f"Bad poses: {bad_frames} ({bad_frames/len(frame_results):.2%})")
                
                if output_path:
                    print(f"Annotated video saved to: {output_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜ - í’€ì—…â†’ëŸ°ì§€ êµì²´"""
    parser = argparse.ArgumentParser(description='Real-time Exercise Pose Analysis (í’€ì—…â†’ëŸ°ì§€ êµì²´)')
    parser.add_argument('--exercise', type=str, default='squat',
                       choices=['bench_press', 'deadlift', 'lunge', 'push_up', 'squat'],  # pull_up â†’ lunge
                       help='Exercise type to analyze')
    parser.add_argument('--mode', type=str, default='camera',
                       choices=['camera', 'video'],
                       help='Analysis mode')
    parser.add_argument('--input', type=str, help='Input video file path (for video mode)')
    parser.add_argument('--output', type=str, help='Output video file path (for video mode)')
    parser.add_argument('--camera', type=int, default=0, help='Camera ID')
    
    args = parser.parse_args()
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = RealtimePoseAnalyzer(args.exercise)
    
    print(f"ğŸš€ í’€ì—…â†’ëŸ°ì§€ êµì²´ ì‹¤ì‹œê°„ ë¶„ì„ê¸° ì‹œì‘")
    print(f"ì§€ì› ìš´ë™: ìŠ¤ì¿¼íŠ¸, í‘¸ì‰¬ì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, ëŸ°ì§€")
    
    if args.mode == 'camera':
        analyzer.run_camera(args.camera)
    elif args.mode == 'video':
        if not args.input:
            print("Error: Input video file is required for video mode")
            return
        analyzer.analyze_video(args.input, args.output)

if __name__ == "__main__":
    main()