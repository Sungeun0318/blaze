"""
í’€ì—… â†’ ëŸ°ì§€ êµì²´ëœ 5ì¢…ëª© ìš´ë™ ë™ì‘ ìë™ ë¶„ë¥˜ ëª¨ë¸
BlazePose ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 5ê°€ì§€ ìš´ë™ ì¢…ëª©ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
ìŠ¤ì¿¼íŠ¸, í‘¸ì‰¬ì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, ëŸ°ì§€ (í’€ì—… ëŒ€ì²´)
processed_data êµ¬ì¡° ì§€ì› ì¶”ê°€
"""

import cv2
import numpy as np
import mediapipe as mp
import json
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os

class ExerciseFeatureExtractor:
    """ìš´ë™ íŠ¹ì§• ì¶”ì¶œê¸° - í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© ì§€ì›"""
    
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=2,
            enable_segmentation=False,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
    
    def extract_landmarks(self, image_path: str) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                return None
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.pose.process(image_rgb)
            
            if results.pose_landmarks:
                landmarks = []
                for landmark in results.pose_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
                return np.array(landmarks)
            return None
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None
    
    def calculate_angles(self, landmarks: np.ndarray) -> np.ndarray:
        """ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚° - í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© íŠ¹ì§• í¬í•¨"""
        def angle_3points(p1, p2, p3):
            """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
            try:
                v1 = p1 - p2
                v2 = p3 - p2
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                return np.degrees(np.arccos(cos_angle))
            except:
                return 0.0
        
        # ëœë“œë§ˆí¬ë¥¼ (x, y, z) í˜•íƒœë¡œ ì¬êµ¬ì„±
        points = landmarks.reshape(-1, 3)
        
        angles = []
        
        # 5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì£¼ìš” ê°ë„ë“¤ ê³„ì‚° (í’€ì—…â†’ëŸ°ì§€ êµì²´)
        angle_configs = [
            # íŒ”ê¿ˆì¹˜ ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í‘¸ì‰¬ì—… êµ¬ë¶„)
            ([11, 13, 15], 'left_elbow'),    # ì™¼ìª½ íŒ”ê¿ˆì¹˜
            ([12, 14, 16], 'right_elbow'),   # ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜
            
            # ì–´ê¹¨ ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í‘¸ì‰¬ì—… êµ¬ë¶„)
            ([13, 11, 23], 'left_shoulder'), # ì™¼ìª½ ì–´ê¹¨
            ([14, 12, 24], 'right_shoulder'), # ì˜¤ë¥¸ìª½ ì–´ê¹¨
            
            # ì—‰ë©ì´ ê°ë„ (ìŠ¤ì¿¼íŠ¸, ë°ë“œë¦¬í”„íŠ¸, ëŸ°ì§€ êµ¬ë¶„ - ì¤‘ìš”!)
            ([11, 23, 25], 'left_hip'),      # ì™¼ìª½ ì—‰ë©ì´
            ([12, 24, 26], 'right_hip'),     # ì˜¤ë¥¸ìª½ ì—‰ë©ì´
            
            # ë¬´ë¦ ê°ë„ (ìŠ¤ì¿¼íŠ¸, ë°ë“œë¦¬í”„íŠ¸, ëŸ°ì§€ êµ¬ë¶„ - ë§¤ìš° ì¤‘ìš”!)
            ([23, 25, 27], 'left_knee'),     # ì™¼ìª½ ë¬´ë¦ (ëŸ°ì§€ ì•ë‹¤ë¦¬)
            ([24, 26, 28], 'right_knee'),    # ì˜¤ë¥¸ìª½ ë¬´ë¦ (ëŸ°ì§€ ë’·ë‹¤ë¦¬)
            
            # ë°œëª© ê°ë„ (ëŸ°ì§€ êµ¬ë¶„ìš© - ìƒˆë¡œ ì¶”ê°€)
            ([25, 27, 31], 'left_ankle'),    # ì™¼ìª½ ë°œëª©
            ([26, 28, 32], 'right_ankle'),   # ì˜¤ë¥¸ìª½ ë°œëª©
            
            # ì²™ì¶” ê°ë„ (ë°ë“œë¦¬í”„íŠ¸, ìŠ¤ì¿¼íŠ¸, ëŸ°ì§€ êµ¬ë¶„)
            ([11, 23, 25], 'spine_upper'),   # ìƒì²´ ì²™ì¶”
            ([23, 25, 27], 'spine_lower'),   # í•˜ì²´ ì²™ì¶”
            
            # ì†ëª© ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í‘¸ì‰¬ì—… êµ¬ë¶„)
            ([13, 15, 17], 'left_wrist'),    # ì™¼ìª½ ì†ëª©
            ([14, 16, 18], 'right_wrist'),   # ì˜¤ë¥¸ìª½ ì†ëª©
            
            # ëª¸í†µ ê°ë„ (í‘¸ì‰¬ì—…, ëŸ°ì§€ êµ¬ë¶„)
            ([11, 12, 23], 'torso_angle'),   # ëª¸í†µ ê°ë„
            
            # ğŸš€ ëŸ°ì§€ êµ¬ë¶„ì„ ìœ„í•œ ì¶”ê°€ ê°ë„ë“¤
            ([11, 23, 24], 'hip_level'),     # ê³¨ë°˜ ìˆ˜í‰ë„
            ([23, 11, 13], 'torso_lean'),    # ìƒì²´ ê¸°ìš¸ê¸°
            ([27, 28, 0], 'foot_separation'), # ë°œ ë²Œë¦¼ ì •ë„ (ëŸ°ì§€ ìŠ¤íƒ ìŠ¤)
        ]
        
        for indices, name in angle_configs:
            try:
                if all(i < len(points) for i in indices):
                    p1, p2, p3 = points[indices[0]][:2], points[indices[1]][:2], points[indices[2]][:2]
                    angle = angle_3points(p1, p2, p3)
                    angles.append(angle)
                else:
                    angles.append(0.0)
            except:
                angles.append(0.0)
        
        return np.array(angles)
    
    def calculate_distances(self, landmarks: np.ndarray) -> np.ndarray:
        """ì£¼ìš” ì‹ ì²´ ë¶€ìœ„ ê°„ ê±°ë¦¬ ê³„ì‚° - í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© íŠ¹ì§•"""
        points = landmarks.reshape(-1, 3)
        
        distances = []
        
        # 5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì£¼ìš” ê±°ë¦¬ë“¤ (í’€ì—…â†’ëŸ°ì§€ êµì²´)
        distance_configs = [
            ([11, 12], 'shoulder_width'),    # ì–´ê¹¨ ë„ˆë¹„
            ([23, 24], 'hip_width'),         # ì—‰ë©ì´ ë„ˆë¹„
            ([27, 28], 'ankle_width'),       # ë°œëª© ë„ˆë¹„ (ëŸ°ì§€ ìŠ¤íƒ ìŠ¤ ì¤‘ìš”!)
            ([11, 23], 'left_torso'),        # ì™¼ìª½ ëª¸í†µ ê¸¸ì´
            ([12, 24], 'right_torso'),       # ì˜¤ë¥¸ìª½ ëª¸í†µ ê¸¸ì´
            ([23, 27], 'left_leg'),          # ì™¼ìª½ ë‹¤ë¦¬ ê¸¸ì´
            ([24, 28], 'right_leg'),         # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¸¸ì´
            ([15, 16], 'hand_distance'),     # ì–‘ì† ê±°ë¦¬ (ë²¤ì¹˜í”„ë ˆìŠ¤, í‘¸ì‰¬ì—…)
            ([0, 23], 'head_to_hip'),        # ë¨¸ë¦¬ì—ì„œ ì—‰ë©ì´ê¹Œì§€
            ([15, 27], 'hand_to_foot'),      # ì†ì—ì„œ ë°œê¹Œì§€ (í‘¸ì‰¬ì—…)
            ([11, 15], 'shoulder_to_hand'),  # ì–´ê¹¨ì—ì„œ ì†ê¹Œì§€
            ([23, 31], 'hip_to_toe'),        # ì—‰ë©ì´ì—ì„œ ë°œëê¹Œì§€
            
            # ğŸš€ ëŸ°ì§€ êµ¬ë¶„ì„ ìœ„í•œ ì¶”ê°€ ê±°ë¦¬ë“¤
            ([27, 31], 'front_foot_length'), # ì•ë°œ ê¸¸ì´ (ëŸ°ì§€)
            ([28, 32], 'back_foot_length'),  # ë’·ë°œ ê¸¸ì´ (ëŸ°ì§€)
            ([25, 26], 'knee_separation'),   # ë¬´ë¦ ê°„ ê±°ë¦¬ (ëŸ°ì§€ ìŠ¤íƒ ìŠ¤)
            ([23, 28], 'hip_to_back_ankle'), # ì—‰ë©ì´ì—ì„œ ë’·ë°œëª©ê¹Œì§€ (ëŸ°ì§€ ê¹Šì´)
        ]
        
        for indices, name in distance_configs:
            try:
                if all(i < len(points) for i in indices):
                    p1, p2 = points[indices[0]][:2], points[indices[1]][:2]
                    dist = np.linalg.norm(p1 - p2)
                    distances.append(dist)
                else:
                    distances.append(0.0)
            except:
                distances.append(0.0)
        
        return np.array(distances)
    
    def calculate_pose_ratios(self, landmarks: np.ndarray) -> np.ndarray:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° - í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© êµ¬ë¶„ íŠ¹ì§•"""
        points = landmarks.reshape(-1, 3)
        
        ratios = []
        
        try:
            # ì£¼ìš” ë¹„ìœ¨ë“¤
            shoulder_width = np.linalg.norm(points[11][:2] - points[12][:2])
            hip_width = np.linalg.norm(points[23][:2] - points[24][:2])
            torso_height = np.linalg.norm(points[11][:2] - points[23][:2])
            leg_length = np.linalg.norm(points[23][:2] - points[27][:2])
            arm_length = np.linalg.norm(points[11][:2] - points[15][:2])
            
            # ğŸš€ ëŸ°ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ì¸¡ì •ê°’ë“¤
            ankle_separation = np.linalg.norm(points[27][:2] - points[28][:2])  # ë°œëª© ê°„ ê±°ë¦¬
            front_leg_bend = np.linalg.norm(points[23][:2] - points[27][:2])   # ì•ë‹¤ë¦¬ êµ½í˜
            back_leg_stretch = np.linalg.norm(points[24][:2] - points[28][:2]) # ë’·ë‹¤ë¦¬ ë»—ìŒ
            
            # ë¹„ìœ¨ ê³„ì‚° (í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© êµ¬ë¶„ìš©)
            ratios.extend([
                shoulder_width / max(hip_width, 0.001),         # ì–´ê¹¨/ì—‰ë©ì´ ë¹„ìœ¨
                torso_height / max(leg_length, 0.001),          # ëª¸í†µ/ë‹¤ë¦¬ ë¹„ìœ¨
                hip_width / max(torso_height, 0.001),           # ì—‰ë©ì´/ëª¸í†µ ë¹„ìœ¨
                arm_length / max(torso_height, 0.001),          # íŒ”/ëª¸í†µ ë¹„ìœ¨
                
                # ë†’ì´ ë¹„ìœ¨ (ìš´ë™ ìì„¸ êµ¬ë¶„)
                points[11][1] / max(points[27][1], 0.001),      # ì–´ê¹¨/ë°œëª© ë†’ì´ ë¹„ìœ¨
                points[23][1] / max(points[27][1], 0.001),      # ì—‰ë©ì´/ë°œëª© ë†’ì´ ë¹„ìœ¨
                points[15][1] / max(points[27][1], 0.001),      # ì†/ë°œ ë†’ì´ ë¹„ìœ¨ (í‘¸ì‰¬ì—…)
                
                # ê°€ë¡œ ë¹„ìœ¨ (ìš´ë™ ë°©í–¥ì„±)
                abs(points[15][0] - points[16][0]) / max(shoulder_width, 0.001),  # ì† ë²Œë¦¼ ì •ë„
                
                # ğŸš€ ëŸ°ì§€ íŠ¹í™” ë¹„ìœ¨ë“¤
                ankle_separation / max(shoulder_width, 0.001),   # ë°œëª©ê°„ê±°ë¦¬/ì–´ê¹¨ë„ˆë¹„ (ëŸ°ì§€ ìŠ¤íƒ ìŠ¤)
                front_leg_bend / max(torso_height, 0.001),       # ì•ë‹¤ë¦¬êµ½í˜/ëª¸í†µë†’ì´ (ëŸ°ì§€ ê¹Šì´)
                back_leg_stretch / max(torso_height, 0.001),     # ë’·ë‹¤ë¦¬ë»—ìŒ/ëª¸í†µë†’ì´ (ëŸ°ì§€ í™•ì¥)
                abs(points[27][1] - points[28][1]) / max(torso_height, 0.001), # ë°œë†’ì´ì°¨ì´/ëª¸í†µë†’ì´
            ])
            
        except:
            ratios = [1.0] * 12  # ëŸ°ì§€ ì¶”ê°€ë¡œ 12ê°œë¡œ ì¦ê°€
        
        return np.array(ratios)
    
    def extract_features(self, image_path: str) -> Optional[np.ndarray]:
        """5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì „ì²´ íŠ¹ì§• ì¶”ì¶œ"""
        landmarks = self.extract_landmarks(image_path)
        if landmarks is None:
            return None
        
        # ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ ì¶”ì¶œ
        angles = self.calculate_angles(landmarks)
        distances = self.calculate_distances(landmarks)
        ratios = self.calculate_pose_ratios(landmarks)
        
        # ëª¨ë“  íŠ¹ì§•ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        features = np.concatenate([angles, distances, ratios])
        
        return features

class ExerciseClassificationModel:
    """í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ (processed_data ì§€ì›)"""
    
    def __init__(self):
        self.feature_extractor = ExerciseFeatureExtractor()
        self.model = RandomForestClassifier(
            n_estimators=300,  # 5ì¢…ëª©ì´ë¯€ë¡œ ë” ë§ì€ íŠ¸ë¦¬
            max_depth=20,      # ë” ê¹Šì€ íŠ¸ë¦¬
            min_samples_split=3,
            min_samples_leaf=1,
            random_state=42,
            class_weight='balanced'  # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
        )
        
        # ğŸš€ í’€ì—… â†’ ëŸ°ì§€ë¡œ ë³€ê²½ëœ 5ì¢…ëª© ë¼ë²¨ ì¸ì½”ë”©
        self.label_encoder = {
            'squat': 0,
            'push_up': 1, 
            'deadlift': 2,
            'bench_press': 3,
            'lunge': 4  # pull_up â†’ lungeë¡œ ë³€ê²½
        }
        self.reverse_encoder = {v: k for k, v in self.label_encoder.items()}
        self.is_trained = False
    
    def prepare_training_data_from_processed(self, processed_data_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """processed_data êµ¬ì¡°ì—ì„œ í›ˆë ¨ ë°ì´í„° ì¤€ë¹„"""
        data_dir = Path(processed_data_path)
        
        features_list = []
        labels_list = []
        
        print("ğŸ” processed_data êµ¬ì¡°ì—ì„œ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        total_processed = 0
        for exercise_name in self.label_encoder.keys():
            exercise_path = data_dir / exercise_name
            if not exercise_path.exists():
                print(f"âš ï¸ Warning: {exercise_path} not found - {exercise_name} ë°ì´í„° ì—†ìŒ")
                continue
            
            print(f"ğŸ“‚ Processing {exercise_name}...")
            
            count = 0
            # goodê³¼ bad í´ë” ëª¨ë‘ ì²˜ë¦¬
            for category in ['good', 'bad']:
                category_path = exercise_path / category
                if not category_path.exists():
                    continue
                
                # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
                image_files = []
                for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                    image_files.extend(list(category_path.glob(ext)))
                
                print(f"  ğŸ“¸ {category}: {len(image_files)} images found")
                
                for img_file in image_files:
                    features = self.feature_extractor.extract_features(str(img_file))
                    if features is not None:
                        features_list.append(features)
                        labels_list.append(self.label_encoder[exercise_name])
                        count += 1
                        
                        if count % 100 == 0:
                            print(f"    Processing: {count} images")
                        
                        # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œí•œ
                        if count >= 1000:
                            break
                
                if count >= 1000:
                    break
            
            total_processed += count
            print(f"  âœ… {exercise_name}: Total {count} images processed")
        
        if not features_list:
            raise ValueError("âŒ No valid training data found in processed_data structure!")
        
        X = np.array(features_list)
        y = np.array(labels_list)
        
        print(f"ğŸ“Š processed_data í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X.shape[0]} samples, {X.shape[1]} features")
        print(f"ğŸ¯ ìš´ë™ë³„ ë°ì´í„° ë¶„í¬:")
        for exercise_name, label in self.label_encoder.items():
            count = np.sum(y == label)
            percentage = (count / len(y)) * 100 if len(y) > 0 else 0
            emoji = {
                'squat': 'ğŸ‹ï¸â€â™€ï¸', 
                'push_up': 'ğŸ’ª', 
                'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 
                'bench_press': 'ğŸ”¥', 
                'lunge': 'ğŸš€'
            }
            print(f"  {emoji.get(exercise_name, 'ğŸ‹ï¸')} {exercise_name}: {count}ê°œ ({percentage:.1f}%)")
        
        return X, y
    
    def prepare_training_data(self, data_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ (ì›ë³¸ êµ¬ì¡° + processed_data êµ¬ì¡° ëª¨ë‘ ì§€ì›)"""
        data_dir = Path(data_path)
        
        # processed_data êµ¬ì¡°ì¸ì§€ í™•ì¸ (squat/good, squat/bad ë“±)
        squat_path = data_dir / 'squat'
        if squat_path.exists() and (squat_path / 'good').exists():
            print("ğŸ“ processed_data êµ¬ì¡° ê°ì§€ë¨")
            return self.prepare_training_data_from_processed(data_path)
        
        # ì›ë³¸ êµ¬ì¡° ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        features_list = []
        labels_list = []
        
        # ğŸš€ í’€ì—… â†’ ëŸ°ì§€ë¡œ ë³€ê²½ëœ 5ì¢…ëª© ë””ë ‰í† ë¦¬ ë§¤í•‘
        exercise_dirs = {
            'squat_exercise': 'squat',
            'push_up_exercise': 'push_up',
            'deadlift_exercise': 'deadlift',
            'bench_press_exercise': 'bench_press',
            'lunge_exercise': 'lunge'  # pull_up_exercise â†’ lunge_exerciseë¡œ ë³€ê²½
        }
        
        print("ğŸ” ì›ë³¸ êµ¬ì¡°ì—ì„œ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        total_processed = 0
        for dir_name, exercise_name in exercise_dirs.items():
            exercise_path = data_dir / dir_name
            if not exercise_path.exists():
                print(f"âš ï¸ Warning: {exercise_path} not found - í•´ë‹¹ ìš´ë™ ë°ì´í„° ì—†ìŒ")
                if exercise_name == 'lunge':
                    print(f"   ğŸ’¡ ëŸ°ì§€ ë°ì´í„°ë¥¼ {exercise_path} í´ë”ì— ì¶”ê°€í•˜ì„¸ìš”!")
                continue
            
            print(f"ğŸ“‚ Processing {exercise_name}...")
            
            # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                image_files.extend(list(exercise_path.glob(ext)))
            
            if not image_files:
                print(f"  âš ï¸ {exercise_name}: ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ")
                continue
            
            count = 0
            for img_file in image_files:
                features = self.feature_extractor.extract_features(str(img_file))
                if features is not None:
                    features_list.append(features)
                    labels_list.append(self.label_encoder[exercise_name])
                    count += 1
                    
                    if count % 50 == 0:
                        print(f"  ğŸ“¸ {exercise_name}: {count} images processed")
                    
                    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œí•œ
                    if count >= 500:
                        break
            
            total_processed += count
            print(f"  âœ… {exercise_name}: Total {count} images")
        
        if not features_list:
            raise ValueError("âŒ No valid training data found!")
        
        X = np.array(features_list)
        y = np.array(labels_list)
        
        print(f"ğŸ“Š ì›ë³¸ êµ¬ì¡° í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X.shape[0]} samples, {X.shape[1]} features")
        print(f"ğŸ¯ ìš´ë™ë³„ ë°ì´í„° ë¶„í¬:")
        for exercise_name, label in self.label_encoder.items():
            count = np.sum(y == label)
            percentage = (count / len(y)) * 100 if len(y) > 0 else 0
            emoji = {
                'squat': 'ğŸ‹ï¸â€â™€ï¸', 
                'push_up': 'ğŸ’ª', 
                'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 
                'bench_press': 'ğŸ”¥', 
                'lunge': 'ğŸš€'
            }
            print(f"  {emoji.get(exercise_name, 'ğŸ‹ï¸')} {exercise_name}: {count}ê°œ ({percentage:.1f}%)")
        
        return X, y
    
    def train(self, data_path: str, test_size: float = 0.2):
        """í’€ì—…â†’ëŸ°ì§€ êµì²´ 5ì¢…ëª© ëª¨ë¸ í›ˆë ¨ (processed_data ì§€ì›)"""
        print("ğŸ§  === processed_data ì§€ì› 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===")
        
        # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
        X, y = self.prepare_training_data(data_path)
        
        # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ í™•ì¸
        unique_labels = np.unique(y)
        if len(unique_labels) < 2:
            raise ValueError("âŒ ìµœì†Œ 2ì¢…ëª© ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        
        print(f"ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ìš´ë™: {len(unique_labels)}ì¢…ëª©")
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  (ê³„ì¸µ ìƒ˜í”Œë§)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"ğŸ“š Training set: {X_train.shape[0]} samples")
        print(f"ğŸ”¬ Test set: {X_test.shape[0]} samples")
        
        # ëª¨ë¸ í›ˆë ¨
        print("âš™ï¸ 5ì¢…ëª© ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        self.model.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… === processed_data ì§€ì› 5ì¢…ëª© í›ˆë ¨ ì™„ë£Œ ===")
        print(f"ğŸ¯ ì •í™•ë„: {accuracy:.3f}")
        print("\nğŸ“ˆ ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìš´ë™ë§Œ í‘œì‹œ
        available_exercises = [self.reverse_encoder[label] for label in unique_labels]
        print(classification_report(y_test, y_pred, 
                                  target_names=available_exercises))
        
        # íŠ¹ì§• ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)
        feature_importance = self.model.feature_importances_
        print(f"\nğŸ” íŠ¹ì§• ì¤‘ìš”ë„ (í‰ê· ): {np.mean(feature_importance):.3f}")
        
        # ìš´ë™ë³„ ì˜ˆì¸¡ ì‹ ë¢°ë„
        print(f"\nğŸ“Š ìš´ë™ë³„ ì˜ˆì¸¡ ì„±ëŠ¥:")
        for exercise in available_exercises:
            label = self.label_encoder[exercise]
            mask = y_test == label
            if np.sum(mask) > 0:
                exercise_accuracy = accuracy_score(y_test[mask], y_pred[mask])
                emoji = {
                    'squat': 'ğŸ‹ï¸â€â™€ï¸', 
                    'push_up': 'ğŸ’ª', 
                    'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 
                    'bench_press': 'ğŸ”¥', 
                    'lunge': 'ğŸš€'
                }
                print(f"  {emoji.get(exercise, 'ğŸ‹ï¸')} {exercise}: {exercise_accuracy:.3f}")
        
        self.is_trained = True
        return accuracy
    
    def predict(self, image_path: str) -> Tuple[str, float]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ 5ì¢…ëª© ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("âŒ Model is not trained yet!")
        
        features = self.feature_extractor.extract_features(image_path)
        if features is None:
            return "unknown", 0.0
        
        # ì˜ˆì¸¡ ë° í™•ë¥ 
        prediction = self.model.predict([features])[0]
        probabilities = self.model.predict_proba([features])[0]
        
        exercise_name = self.reverse_encoder[prediction]
        confidence = probabilities[prediction]
        
        return exercise_name, confidence
    
    def save_model(self, model_path: str):
        """processed_data ì§€ì› 5ì¢…ëª© ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("âŒ Model is not trained yet!")
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
        model_dir = Path(model_path).parent
        model_dir.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'model': self.model,
            'label_encoder': self.label_encoder,
            'reverse_encoder': self.reverse_encoder,
            'is_trained': self.is_trained,
            'supported_exercises': list(self.label_encoder.keys()),
            'feature_count': len(self.label_encoder),
            'version': 'processed_data_support_v1.0',
            'data_structures_supported': ['original_images', 'processed_data'],
            'changelog': {
                'added': 'processed_data structure support',
                'replaced': 'pull_up â†’ lunge',
                'maintained': ['squat', 'push_up', 'deadlift', 'bench_press']
            }
        }
        
        joblib.dump(model_data, model_path)
        print(f"ğŸ’¾ processed_data ì§€ì› 5ì¢…ëª© ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
        print(f"ğŸ¯ ì§€ì› ìš´ë™: {', '.join(self.label_encoder.keys())}")
        print(f"ğŸ“ ì§€ì› êµ¬ì¡°: ì›ë³¸ ì´ë¯¸ì§€ + processed_data")
    
    def load_model(self, model_path: str):
        """processed_data ì§€ì› 5ì¢…ëª© ëª¨ë¸ ë¡œë“œ"""
        try:
            model_data = joblib.load(model_path)
            
            self.model = model_data['model']
            self.label_encoder = model_data['label_encoder']
            self.reverse_encoder = model_data['reverse_encoder']
            self.is_trained = model_data['is_trained']
            
            # ë²„ì „ ì •ë³´ í™•ì¸
            version = model_data.get('version', 'unknown')
            supported_exercises = model_data.get('supported_exercises', list(self.label_encoder.keys()))
            
            print(f"ğŸ“¥ processed_data ì§€ì› ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            print(f"ğŸ¯ ì§€ì› ìš´ë™ ({len(supported_exercises)}ì¢…ëª©): {', '.join(supported_exercises)}")
            print(f"ğŸ“‹ ëª¨ë¸ ë²„ì „: {version}")
            
            data_structures = model_data.get('data_structures_supported', ['original_images'])
            if 'processed_data' in data_structures:
                print(f"ğŸ“ processed_data êµ¬ì¡° ì§€ì› âœ…")
            
            return True
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (processed_data ì§€ì›)"""
    import argparse
    
    parser = argparse.ArgumentParser(description='processed_data ì§€ì› 5ì¢…ëª© Exercise Classification Model')
    parser.add_argument('--mode', type=str, required=True,
                       choices=['train', 'predict', 'evaluate'],
                       help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--data_path', type=str, default='./processed_data',
                       help='í›ˆë ¨ ë°ì´í„° ê²½ë¡œ (processed_data ë˜ëŠ” ì›ë³¸ êµ¬ì¡°)')
    parser.add_argument('--model_path', type=str, default='models/exercise_classifier.pkl',
                       help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--image', type=str, help='ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ìš©')
    parser.add_argument('--test_data', type=str, help='ë³„ë„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ')
    
    args = parser.parse_args()
    
    if args.mode == 'train':
        # processed_data ì§€ì› 5ì¢…ëª© ëª¨ë¸ í›ˆë ¨
        model = ExerciseClassificationModel()
        try:
            print("ğŸš€ processed_data ì§€ì› 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            print("ì§€ì› ìš´ë™: ìŠ¤ì¿¼íŠ¸, í‘¸ì‰¬ì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, ëŸ°ì§€")
            print("ğŸ“ ì§€ì› êµ¬ì¡°: ì›ë³¸ ì´ë¯¸ì§€ í´ë” + processed_data í´ë”")
            
            accuracy = model.train(args.data_path)
            model.save_model(args.model_path)
            
            print(f"\nğŸ‰ processed_data ì§€ì› 5ì¢…ëª© í›ˆë ¨ ì™„ë£Œ! ì •í™•ë„: {accuracy:.3f}")
            print("ğŸ’¡ ì‹¤ì‹œê°„ ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´:")
            print("   python main.py --mode realtime")
            
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return 1
        
    elif args.mode == 'predict':
        # ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
        if not args.image:
            print("âŒ --image ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤")
            return 1
        
        model = ExerciseClassificationModel()
        if model.load_model(args.model_path):
            try:
                exercise, confidence = model.predict(args.image)
                
                # ê²°ê³¼ ì¶œë ¥
                emoji = {
                    'squat': 'ğŸ‹ï¸â€â™€ï¸', 
                    'push_up': 'ğŸ’ª', 
                    'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 
                    'bench_press': 'ğŸ”¥', 
                    'lunge': 'ğŸš€'
                }
                print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
                print(f"  {emoji.get(exercise, 'ğŸ‹ï¸')} ìš´ë™: {exercise.upper()}")
                print(f"  ğŸ“Š ì‹ ë¢°ë„: {confidence:.3f} ({confidence*100:.1f}%)")
                
                if confidence > 0.8:
                    print("  âœ… ë†’ì€ ì‹ ë¢°ë„ - ì •í™•í•œ ì˜ˆì¸¡")
                elif confidence > 0.6:
                    print("  âš ï¸ ë³´í†µ ì‹ ë¢°ë„ - ì¶”ê°€ í™•ì¸ ê¶Œì¥")
                else:
                    print("  âŒ ë‚®ì€ ì‹ ë¢°ë„ - ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡")
                    
            except Exception as e:
                print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                return 1
        else:
            return 1
    
    elif args.mode == 'evaluate':
        # ëª¨ë¸ í‰ê°€
        model = ExerciseClassificationModel()
        if model.load_model(args.model_path):
            print("ğŸ’¡ ëª¨ë¸ ì •ë³´:")
            print(f"  ì§€ì› ìš´ë™: {len(model.label_encoder)}ì¢…ëª©")
            print(f"  í›ˆë ¨ ìƒíƒœ: {'âœ… ì™„ë£Œ' if model.is_trained else 'âŒ ë¯¸ì™„ë£Œ'}")
            print(f"  ìš´ë™ ëª©ë¡: {', '.join(model.label_encoder.keys())}")
            print(f"  ğŸ“ processed_data êµ¬ì¡° ì§€ì›")
        else:
            return 1
    
    return 0

if __name__ == "__main__":
    exit(main())