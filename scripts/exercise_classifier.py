"""
5ì¢…ëª© ìš´ë™ ë™ì‘ ìë™ ë¶„ë¥˜ ëª¨ë¸
BlazePose ëœë“œë§ˆí¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 5ê°€ì§€ ìš´ë™ ì¢…ëª©ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
ìŠ¤ì¿¼íŠ¸, í‘¸ì‹œì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…
"""

import cv2
import numpy as np
import mediapipe as mp
import json
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os

class ExerciseFeatureExtractor:
    """ìš´ë™ íŠ¹ì§• ì¶”ì¶œê¸° - 5ì¢…ëª© ì§€ì›"""
    
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=2,
            enable_segmentation=False,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
    
    def extract_landmarks(self, image_path: str) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                return None
            
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.pose.process(image_rgb)
            
            if results.pose_landmarks:
                landmarks = []
                for landmark in results.pose_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
                return np.array(landmarks)
            return None
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None
    
    def calculate_angles(self, landmarks: np.ndarray) -> np.ndarray:
        """ì£¼ìš” ê´€ì ˆ ê°ë„ ê³„ì‚° - 5ì¢…ëª© íŠ¹ì§• í¬í•¨"""
        def angle_3points(p1, p2, p3):
            """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
            try:
                v1 = p1 - p2
                v2 = p3 - p2
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                cos_angle = np.clip(cos_angle, -1.0, 1.0)
                return np.degrees(np.arccos(cos_angle))
            except:
                return 0.0
        
        # ëœë“œë§ˆí¬ë¥¼ (x, y, z) í˜•íƒœë¡œ ì¬êµ¬ì„±
        points = landmarks.reshape(-1, 3)
        
        angles = []
        
        # 5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì£¼ìš” ê°ë„ë“¤ ê³„ì‚°
        angle_configs = [
            # íŒ”ê¿ˆì¹˜ ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…, í‘¸ì‹œì—… êµ¬ë¶„)
            ([11, 13, 15], 'left_elbow'),    # ì™¼ìª½ íŒ”ê¿ˆì¹˜
            ([12, 14, 16], 'right_elbow'),   # ì˜¤ë¥¸ìª½ íŒ”ê¿ˆì¹˜
            
            # ì–´ê¹¨ ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—… êµ¬ë¶„)
            ([13, 11, 23], 'left_shoulder'), # ì™¼ìª½ ì–´ê¹¨
            ([14, 12, 24], 'right_shoulder'), # ì˜¤ë¥¸ìª½ ì–´ê¹¨
            
            # ì—‰ë©ì´ ê°ë„ (ìŠ¤ì¿¼íŠ¸, ë°ë“œë¦¬í”„íŠ¸ êµ¬ë¶„)
            ([11, 23, 25], 'left_hip'),      # ì™¼ìª½ ì—‰ë©ì´
            ([12, 24, 26], 'right_hip'),     # ì˜¤ë¥¸ìª½ ì—‰ë©ì´
            
            # ë¬´ë¦ ê°ë„ (ìŠ¤ì¿¼íŠ¸, ë°ë“œë¦¬í”„íŠ¸ êµ¬ë¶„)
            ([23, 25, 27], 'left_knee'),     # ì™¼ìª½ ë¬´ë¦
            ([24, 26, 28], 'right_knee'),    # ì˜¤ë¥¸ìª½ ë¬´ë¦
            
            # ë°œëª© ê°ë„
            ([25, 27, 31], 'left_ankle'),    # ì™¼ìª½ ë°œëª©
            ([26, 28, 32], 'right_ankle'),   # ì˜¤ë¥¸ìª½ ë°œëª©
            
            # ì²™ì¶” ê°ë„ (ë°ë“œë¦¬í”„íŠ¸, ìŠ¤ì¿¼íŠ¸ êµ¬ë¶„)
            ([11, 23, 25], 'spine_upper'),   # ìƒì²´ ì²™ì¶”
            ([23, 25, 27], 'spine_lower'),   # í•˜ì²´ ì²™ì¶”
            
            # ì†ëª© ê°ë„ (ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—… êµ¬ë¶„)
            ([13, 15, 17], 'left_wrist'),    # ì™¼ìª½ ì†ëª©
            ([14, 16, 18], 'right_wrist'),   # ì˜¤ë¥¸ìª½ ì†ëª©
            
            # ëª¸í†µ ê°ë„ (í‘¸ì‹œì—… êµ¬ë¶„)
            ([11, 12, 23], 'torso_angle'),   # ëª¸í†µ ê°ë„
        ]
        
        for indices, name in angle_configs:
            try:
                if all(i < len(points) for i in indices):
                    p1, p2, p3 = points[indices[0]][:2], points[indices[1]][:2], points[indices[2]][:2]
                    angle = angle_3points(p1, p2, p3)
                    angles.append(angle)
                else:
                    angles.append(0.0)
            except:
                angles.append(0.0)
        
        return np.array(angles)
    
    def calculate_distances(self, landmarks: np.ndarray) -> np.ndarray:
        """ì£¼ìš” ì‹ ì²´ ë¶€ìœ„ ê°„ ê±°ë¦¬ ê³„ì‚° - 5ì¢…ëª© íŠ¹ì§•"""
        points = landmarks.reshape(-1, 3)
        
        distances = []
        
        # 5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì£¼ìš” ê±°ë¦¬ë“¤
        distance_configs = [
            ([11, 12], 'shoulder_width'),    # ì–´ê¹¨ ë„ˆë¹„
            ([23, 24], 'hip_width'),         # ì—‰ë©ì´ ë„ˆë¹„
            ([27, 28], 'ankle_width'),       # ë°œëª© ë„ˆë¹„
            ([11, 23], 'left_torso'),        # ì™¼ìª½ ëª¸í†µ ê¸¸ì´
            ([12, 24], 'right_torso'),       # ì˜¤ë¥¸ìª½ ëª¸í†µ ê¸¸ì´
            ([23, 27], 'left_leg'),          # ì™¼ìª½ ë‹¤ë¦¬ ê¸¸ì´
            ([24, 28], 'right_leg'),         # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬ ê¸¸ì´
            ([15, 16], 'hand_distance'),     # ì–‘ì† ê±°ë¦¬ (ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…)
            ([0, 23], 'head_to_hip'),        # ë¨¸ë¦¬ì—ì„œ ì—‰ë©ì´ê¹Œì§€
            ([15, 27], 'hand_to_foot'),      # ì†ì—ì„œ ë°œê¹Œì§€ (í‘¸ì‹œì—…)
            ([11, 15], 'shoulder_to_hand'),  # ì–´ê¹¨ì—ì„œ ì†ê¹Œì§€
            ([23, 31], 'hip_to_toe'),        # ì—‰ë©ì´ì—ì„œ ë°œëê¹Œì§€
        ]
        
        for indices, name in distance_configs:
            try:
                if all(i < len(points) for i in indices):
                    p1, p2 = points[indices[0]][:2], points[indices[1]][:2]
                    dist = np.linalg.norm(p1 - p2)
                    distances.append(dist)
                else:
                    distances.append(0.0)
            except:
                distances.append(0.0)
        
        return np.array(distances)
    
    def calculate_pose_ratios(self, landmarks: np.ndarray) -> np.ndarray:
        """ì‹ ì²´ ë¹„ìœ¨ ê³„ì‚° - 5ì¢…ëª© êµ¬ë¶„ íŠ¹ì§•"""
        points = landmarks.reshape(-1, 3)
        
        ratios = []
        
        try:
            # ì£¼ìš” ë¹„ìœ¨ë“¤
            shoulder_width = np.linalg.norm(points[11][:2] - points[12][:2])
            hip_width = np.linalg.norm(points[23][:2] - points[24][:2])
            torso_height = np.linalg.norm(points[11][:2] - points[23][:2])
            leg_length = np.linalg.norm(points[23][:2] - points[27][:2])
            arm_length = np.linalg.norm(points[11][:2] - points[15][:2])
            
            # ë¹„ìœ¨ ê³„ì‚° (5ì¢…ëª© êµ¬ë¶„ìš©)
            ratios.extend([
                shoulder_width / max(hip_width, 0.001),      # ì–´ê¹¨/ì—‰ë©ì´ ë¹„ìœ¨
                torso_height / max(leg_length, 0.001),       # ëª¸í†µ/ë‹¤ë¦¬ ë¹„ìœ¨
                hip_width / max(torso_height, 0.001),        # ì—‰ë©ì´/ëª¸í†µ ë¹„ìœ¨
                arm_length / max(torso_height, 0.001),       # íŒ”/ëª¸í†µ ë¹„ìœ¨
                
                # ë†’ì´ ë¹„ìœ¨ (ìš´ë™ ìì„¸ êµ¬ë¶„)
                points[11][1] / max(points[27][1], 0.001),   # ì–´ê¹¨/ë°œëª© ë†’ì´ ë¹„ìœ¨
                points[23][1] / max(points[27][1], 0.001),   # ì—‰ë©ì´/ë°œëª© ë†’ì´ ë¹„ìœ¨
                points[15][1] / max(points[27][1], 0.001),   # ì†/ë°œ ë†’ì´ ë¹„ìœ¨ (í‘¸ì‹œì—…, í’€ì—…)
                
                # ê°€ë¡œ ë¹„ìœ¨ (ìš´ë™ ë°©í–¥ì„±)
                abs(points[15][0] - points[16][0]) / max(shoulder_width, 0.001),  # ì† ë²Œë¦¼ ì •ë„
            ])
            
        except:
            ratios = [1.0] * 8
        
        return np.array(ratios)
    
    def extract_features(self, image_path: str) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ì—ì„œ 5ì¢…ëª© êµ¬ë¶„ì„ ìœ„í•œ ì „ì²´ íŠ¹ì§• ì¶”ì¶œ"""
        landmarks = self.extract_landmarks(image_path)
        if landmarks is None:
            return None
        
        # ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ ì¶”ì¶œ
        angles = self.calculate_angles(landmarks)
        distances = self.calculate_distances(landmarks)
        ratios = self.calculate_pose_ratios(landmarks)
        
        # ëª¨ë“  íŠ¹ì§•ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        features = np.concatenate([angles, distances, ratios])
        
        return features

class ExerciseClassificationModel:
    """5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self):
        self.feature_extractor = ExerciseFeatureExtractor()
        self.model = RandomForestClassifier(
            n_estimators=300,  # 5ì¢…ëª©ì´ë¯€ë¡œ ë” ë§ì€ íŠ¸ë¦¬
            max_depth=20,      # ë” ê¹Šì€ íŠ¸ë¦¬
            min_samples_split=3,
            min_samples_leaf=1,
            random_state=42,
            class_weight='balanced'  # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
        )
        # 5ì¢…ëª© ë¼ë²¨ ì¸ì½”ë”©
        self.label_encoder = {
            'squat': 0,
            'push_up': 1, 
            'deadlift': 2,
            'bench_press': 3,
            'pull_up': 4
        }
        self.reverse_encoder = {v: k for k, v in self.label_encoder.items()}
        self.is_trained = False
    
    def prepare_training_data(self, data_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """5ì¢…ëª© í›ˆë ¨ ë°ì´í„° ì¤€ë¹„"""
        data_dir = Path(data_path)
        
        features_list = []
        labels_list = []
        
        # 5ì¢…ëª© ë””ë ‰í† ë¦¬ ë§¤í•‘
        exercise_dirs = {
            'squat_exercise': 'squat',
            'push_up_exercise': 'push_up',
            'deadlift_exercise': 'deadlift',
            'bench_press_exercise': 'bench_press',
            'pull_up_exercise': 'pull_up'
        }
        
        print("ğŸ” 5ì¢…ëª© í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        total_processed = 0
        for dir_name, exercise_name in exercise_dirs.items():
            exercise_path = data_dir / dir_name
            if not exercise_path.exists():
                print(f"âš ï¸ Warning: {exercise_path} not found - í•´ë‹¹ ìš´ë™ ë°ì´í„° ì—†ìŒ")
                continue
            
            print(f"ğŸ“‚ Processing {exercise_name}...")
            
            # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
            image_files = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                image_files.extend(list(exercise_path.glob(ext)))
            
            if not image_files:
                print(f"  âš ï¸ {exercise_name}: ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ")
                continue
            
            count = 0
            for img_file in image_files:
                features = self.feature_extractor.extract_features(str(img_file))
                if features is not None:
                    features_list.append(features)
                    labels_list.append(self.label_encoder[exercise_name])
                    count += 1
                    
                    if count % 50 == 0:
                        print(f"  ğŸ“¸ {exercise_name}: {count} images processed")
                    
                    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì œí•œ
                    if count >= 500:
                        break
            
            total_processed += count
            print(f"  âœ… {exercise_name}: Total {count} images")
        
        if not features_list:
            raise ValueError("âŒ No valid training data found!")
        
        X = np.array(features_list)
        y = np.array(labels_list)
        
        print(f"ğŸ“Š 5ì¢…ëª© Training data prepared: {X.shape[0]} samples, {X.shape[1]} features")
        print(f"ğŸ¯ ìš´ë™ë³„ ë°ì´í„° ë¶„í¬:")
        for exercise_name, label in self.label_encoder.items():
            count = np.sum(y == label)
            percentage = (count / len(y)) * 100 if len(y) > 0 else 0
            emoji = {'squat': 'ğŸ‹ï¸â€â™€ï¸', 'push_up': 'ğŸ’ª', 'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 'bench_press': 'ğŸ”¥', 'pull_up': 'ğŸ’¯'}
            print(f"  {emoji.get(exercise_name, 'ğŸ‹ï¸')} {exercise_name}: {count}ê°œ ({percentage:.1f}%)")
        
        return X, y
    
    def train(self, data_path: str, test_size: float = 0.2):
        """5ì¢…ëª© ëª¨ë¸ í›ˆë ¨"""
        print("ğŸ§  === 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===")
        
        # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
        X, y = self.prepare_training_data(data_path)
        
        # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ í™•ì¸
        unique_labels = np.unique(y)
        if len(unique_labels) < 2:
            raise ValueError("âŒ ìµœì†Œ 2ì¢…ëª© ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        
        print(f"ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ìš´ë™: {len(unique_labels)}ì¢…ëª©")
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  (ê³„ì¸µ ìƒ˜í”Œë§)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"ğŸ“š Training set: {X_train.shape[0]} samples")
        print(f"ğŸ”¬ Test set: {X_test.shape[0]} samples")
        
        # ëª¨ë¸ í›ˆë ¨
        print("âš™ï¸ 5ì¢…ëª© ëª¨ë¸ í›ˆë ¨ ì¤‘...")
        self.model.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… === 5ì¢…ëª© í›ˆë ¨ ì™„ë£Œ ===")
        print(f"ğŸ¯ ì •í™•ë„: {accuracy:.3f}")
        print("\nğŸ“ˆ ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìš´ë™ë§Œ í‘œì‹œ
        available_exercises = [self.reverse_encoder[label] for label in unique_labels]
        print(classification_report(y_test, y_pred, 
                                  target_names=available_exercises))
        
        # íŠ¹ì§• ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)
        feature_importance = self.model.feature_importances_
        print(f"\nğŸ” íŠ¹ì§• ì¤‘ìš”ë„ (í‰ê· ): {np.mean(feature_importance):.3f}")
        
        # ìš´ë™ë³„ ì˜ˆì¸¡ ì‹ ë¢°ë„
        print(f"\nğŸ“Š ìš´ë™ë³„ ì˜ˆì¸¡ ì„±ëŠ¥:")
        for exercise in available_exercises:
            label = self.label_encoder[exercise]
            mask = y_test == label
            if np.sum(mask) > 0:
                exercise_accuracy = accuracy_score(y_test[mask], y_pred[mask])
                emoji = {'squat': 'ğŸ‹ï¸â€â™€ï¸', 'push_up': 'ğŸ’ª', 'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 'bench_press': 'ğŸ”¥', 'pull_up': 'ğŸ’¯'}
                print(f"  {emoji.get(exercise, 'ğŸ‹ï¸')} {exercise}: {exercise_accuracy:.3f}")
        
        self.is_trained = True
        return accuracy
    
    def predict(self, image_path: str) -> Tuple[str, float]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ 5ì¢…ëª© ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("âŒ Model is not trained yet!")
        
        features = self.feature_extractor.extract_features(image_path)
        if features is None:
            return "unknown", 0.0
        
        # ì˜ˆì¸¡ ë° í™•ë¥ 
        prediction = self.model.predict([features])[0]
        probabilities = self.model.predict_proba([features])[0]
        
        exercise_name = self.reverse_encoder[prediction]
        confidence = probabilities[prediction]
        
        return exercise_name, confidence
    
    def predict_batch(self, image_paths: List[str]) -> List[Tuple[str, float]]:
        """ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì˜ˆì¸¡"""
        results = []
        
        print(f"ğŸ”„ Batch prediction for {len(image_paths)} images...")
        for i, img_path in enumerate(image_paths):
            if i % 100 == 0:
                print(f"  Progress: {i}/{len(image_paths)}")
            
            result = self.predict(img_path)
            results.append(result)
        
        return results
    
    def get_prediction_confidence_stats(self, image_paths: List[str]) -> Dict:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ í†µê³„"""
        predictions = self.predict_batch(image_paths)
        
        exercise_confidences = {}
        for exercise, confidence in predictions:
            if exercise not in exercise_confidences:
                exercise_confidences[exercise] = []
            exercise_confidences[exercise].append(confidence)
        
        stats = {}
        for exercise, confidences in exercise_confidences.items():
            stats[exercise] = {
                'count': len(confidences),
                'mean_confidence': np.mean(confidences),
                'std_confidence': np.std(confidences),
                'min_confidence': np.min(confidences),
                'max_confidence': np.max(confidences)
            }
        
        return stats
    
    def save_model(self, model_path: str):
        """5ì¢…ëª© ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("âŒ Model is not trained yet!")
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
        model_dir = Path(model_path).parent
        model_dir.mkdir(parents=True, exist_ok=True)
        
        model_data = {
            'model': self.model,
            'label_encoder': self.label_encoder,
            'reverse_encoder': self.reverse_encoder,
            'is_trained': self.is_trained,
            'supported_exercises': list(self.label_encoder.keys()),
            'feature_count': len(self.label_encoder),
            'version': '5-exercise-v1.0'
        }
        
        joblib.dump(model_data, model_path)
        print(f"ğŸ’¾ 5ì¢…ëª© ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
        print(f"ğŸ¯ ì§€ì› ìš´ë™: {', '.join(self.label_encoder.keys())}")
    
    def load_model(self, model_path: str):
        """5ì¢…ëª© ëª¨ë¸ ë¡œë“œ"""
        try:
            model_data = joblib.load(model_path)
            
            self.model = model_data['model']
            self.label_encoder = model_data['label_encoder']
            self.reverse_encoder = model_data['reverse_encoder']
            self.is_trained = model_data['is_trained']
            
            # ë²„ì „ ì •ë³´ í™•ì¸
            version = model_data.get('version', 'unknown')
            supported_exercises = model_data.get('supported_exercises', list(self.label_encoder.keys()))
            
            print(f"ğŸ“¥ 5ì¢…ëª© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            print(f"ğŸ¯ ì§€ì› ìš´ë™ ({len(supported_exercises)}ì¢…ëª©): {', '.join(supported_exercises)}")
            print(f"ğŸ“‹ ëª¨ë¸ ë²„ì „: {version}")
            
            return True
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False
    
    def evaluate_model_performance(self, test_data_path: str = None):
        """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        if not self.is_trained:
            print("âŒ ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        if test_data_path:
            print(f"ğŸ”¬ ë³„ë„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€: {test_data_path}")
            X_test, y_test = self.prepare_training_data(test_data_path)
            y_pred = self.model.predict(X_test)
            
            accuracy = accuracy_score(y_test, y_pred)
            print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.3f}")
            
            return {
                'accuracy': accuracy,
                'predictions': y_pred,
                'true_labels': y_test
            }
        else:
            print("ğŸ’¡ ëª¨ë¸ ì •ë³´:")
            print(f"  ì§€ì› ìš´ë™: {len(self.label_encoder)}ì¢…ëª©")
            print(f"  í›ˆë ¨ ìƒíƒœ: {'âœ… ì™„ë£Œ' if self.is_trained else 'âŒ ë¯¸ì™„ë£Œ'}")
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='5ì¢…ëª© Exercise Classification Model')
    parser.add_argument('--mode', type=str, required=True,
                       choices=['train', 'predict', 'evaluate'],
                       help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--data_path', type=str, default='./data/training_images',
                       help='í›ˆë ¨ ë°ì´í„° ê²½ë¡œ')
    parser.add_argument('--model_path', type=str, default='models/exercise_classifier.pkl',
                       help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--image', type=str, help='ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ìš©')
    parser.add_argument('--test_data', type=str, help='ë³„ë„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ')
    
    args = parser.parse_args()
    
    if args.mode == 'train':
        # 5ì¢…ëª© ëª¨ë¸ í›ˆë ¨
        model = ExerciseClassificationModel()
        try:
            print("ğŸ‹ï¸ 5ì¢…ëª© ìš´ë™ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            print("ì§€ì› ìš´ë™: ìŠ¤ì¿¼íŠ¸, í‘¸ì‹œì—…, ë°ë“œë¦¬í”„íŠ¸, ë²¤ì¹˜í”„ë ˆìŠ¤, í’€ì—…")
            
            accuracy = model.train(args.data_path)
            model.save_model(args.model_path)
            
            print(f"\nğŸ‰ 5ì¢…ëª© í›ˆë ¨ ì™„ë£Œ! ì •í™•ë„: {accuracy:.3f}")
            print("ğŸ’¡ ì‹¤ì‹œê°„ ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´:")
            print("   python main.py --mode realtime")
            
        except Exception as e:
            print(f"âŒ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            return 1
        
    elif args.mode == 'predict':
        # ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
        if not args.image:
            print("âŒ --image ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤")
            return 1
        
        model = ExerciseClassificationModel()
        if model.load_model(args.model_path):
            try:
                exercise, confidence = model.predict(args.image)
                
                # ê²°ê³¼ ì¶œë ¥
                emoji = {'squat': 'ğŸ‹ï¸â€â™€ï¸', 'push_up': 'ğŸ’ª', 'deadlift': 'ğŸ‹ï¸â€â™‚ï¸', 'bench_press': 'ğŸ”¥', 'pull_up': 'ğŸ’¯'}
                print(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
                print(f"  {emoji.get(exercise, 'ğŸ‹ï¸')} ìš´ë™: {exercise.upper()}")
                print(f"  ğŸ“Š ì‹ ë¢°ë„: {confidence:.3f} ({confidence*100:.1f}%)")
                
                if confidence > 0.8:
                    print("  âœ… ë†’ì€ ì‹ ë¢°ë„ - ì •í™•í•œ ì˜ˆì¸¡")
                elif confidence > 0.6:
                    print("  âš ï¸ ë³´í†µ ì‹ ë¢°ë„ - ì¶”ê°€ í™•ì¸ ê¶Œì¥")
                else:
                    print("  âŒ ë‚®ì€ ì‹ ë¢°ë„ - ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡")
                    
            except Exception as e:
                print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                return 1
        else:
            return 1
    
    elif args.mode == 'evaluate':
        # ëª¨ë¸ í‰ê°€
        model = ExerciseClassificationModel()
        if model.load_model(args.model_path):
            model.evaluate_model_performance(args.test_data)
        else:
            return 1
    
    return 0

if __name__ == "__main__":
    exit(main())